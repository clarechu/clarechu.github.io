{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[{"title":"About","date":"2021-03-11T10:57:45.843Z","updated":"2021-03-11T10:57:45.843Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"关于我大家好！ 欢迎来到我的个人网站！ 一个有5年工作经验的码农,主要从事的golang后台开发主要的研究的方向是istio和kubernetes.这里收集了个人认为日常实用的代码， 网上收集的实用代码以及个人感兴趣的各种知识记录。 以下为我给自己设立的要求： 记录日常复习中带有重复利用价值的代码及介绍 记录日常突发奇想的算法及想法 记录自学过程中的代码及介绍 记录解决难题过程中的代码及介绍 积极生产小工具和复用性极高的代码以形成自己的个人代码库 以上要求做不到的话， 就随便写点什么吧 从前的我没有把知识记录下来的习惯， 希望现在可以通过我的个人网站来养成这种习惯。 关于我的信息昵称： ClareChu目前职业： golang工程师专业： 软件开发目前居住地： 深圳家乡： 湖北武汉爱好： 看书、 玩游戏、 看动漫、 躺着、 敲代码 主要喜欢看海贼王和柯南 火影啥啥啥的哈哈，随便附上我最爱动漫的一张图片 联系方式QQ: 1062186165Email: &#x31;&#x30;&#54;&#x32;&#49;&#x38;&#54;&#49;&#54;&#53;&#x40;&#x71;&#x71;&#x2e;&#x63;&#x6f;&#x6d;Github: https://github.com/ClareChu"}],"posts":[{"title":"集群内部负载均衡 lb","slug":"k8s/lb","date":"2021-04-07T14:50:01.000Z","updated":"2021-06-28T05:58:08.059Z","comments":true,"path":"2021/04/07/k8s/lb/","link":"","permalink":"http://example.com/2021/04/07/k8s/lb/","excerpt":"","text":"集群内部负载均衡 lbk8s的LoadBalancer类型的Service依赖云服务商的Load Balancer, 如阿里云的slb。 当我们把k8s部署在私有云时，需要简单的LoadBalancer来验证工作，开源的metallb就是一个不错的选择。 MetalLB支持2种 一种是Layer2 、BGP MetalLB 安装123kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/namespace.yaml;kubectl create secret generic -n metallb-system memberlist --from-literal=secretkey=&quot;$(openssl rand -base64 128)&quot;;kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/metallb.yaml; 前提条件MetalLB需要以下功能才能发挥作用： 一个 Kubernetes 运行Kubernetes 1.13.0或更高版本的集群，尚不具有网络负载平衡功能。 一个 集群网络配置 可以与MetalLB共存。 一些用于MetalLB的IPv4地址。 使用BGP工作模式时，您将需要一台或多台能够讲话的路由器 BGP协议。 节点之间必须允许端口7946（TCP＆UDP）上的流量，具体取决于 会员列表。 GBP 配置 12345678910111213141516apiVersion: v1kind: ConfigMapmetadata: namespace: metallb-system name: configdata: config: | peers: - peer-address: 10.0.0.1 peer-asn: 64501 my-asn: 64500 address-pools: - name: default protocol: bgp addresses: - 192.168.10.0/24 创建configmap1kubectl apply -f configmap.yaml","categories":[],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://example.com/tags/kubernetes/"}]},{"title":"如何在本地调试istio","slug":"k8s/istio/debug-istio","date":"2021-03-22T05:40:42.000Z","updated":"2021-03-26T05:30:22.062Z","comments":true,"path":"2021/03/22/k8s/istio/debug-istio/","link":"","permalink":"http://example.com/2021/03/22/k8s/istio/debug-istio/","excerpt":"","text":"本文档主要是帮助我们如何在本地使用调试istio 因为我们使用的istio都是在1.8.4上面做的,所以我在下面的讲解的版本也是在istio release-1.8.4版本上面进行 istio 核心模块有两个 pilot-discovery: 这个模块就是我们的istiod istio/pilot/pilot-discovery 目录下 pilot-agent: 这个模块 就是proxy istio/pilot/pilot-discovery 目录下 如果我们使用kind 则需要 –config trustworthy-jwt.yaml 1234567891011121314151617181920apiVersion: kind.x-k8s.io/v1alpha4kind: ClusterkubeadmConfigPatches: - | apiVersion: kubeadm.k8s.io/v1beta2 kind: ClusterConfiguration metadata: name: config etcd: local: # Run etcd in a tmpfs (in RAM) for performance improvements dataDir: /tmp/kind-cluster-etcd apiServer: extraArgs: &quot;service-account-issuer&quot;: &quot;kubernetes.default.svc&quot; &quot;service-account-signing-key-file&quot;: &quot;/etc/kubernetes/pki/sa.key&quot;containerdConfigPatches: - |- [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;localhost:5000&quot;] endpoint = [&quot;http://kind-registry:5000&quot;] 运行kind1$ kind create cluster --image docker.io/kindest/node:v1.17.5 --config trustworthy-jwt.yaml --name kind-2 本地代理pilot-discovery12# 安装istio$ istioctl install 等待istio 安装完成以后我们将 istiod的流量转到本地，主要目的是为了更改endpoint 使用外部 istiod 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 设置外部 IP$ export ip=192.168.110.206$ kubectl -n istio-system delete svc istiod$ kubectl -n istio-system delete endpoints istiod$ cat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1kind: Servicemetadata: name: istiod namespace: istio-systemspec: ports: - name: grpc-xds port: 15010 - name: https-dns port: 15012 - name: https-webhook port: 443 targetPort: 15017 - name: http-monitoring port: 15014---apiVersion: v1kind: Endpointsmetadata: name: istiod namespace: istio-systemsubsets:- addresses: - ip: $&#123;ip&#125; ports: - name: https-dns port: 15012 protocol: TCP - name: grpc-xds port: 15010 protocol: TCP - name: https-webhook port: 15017 protocol: TCP - name: http-monitoring port: 15014 protocol: TCPEOF 还原istio 的svc地址 使svc指向 集群内部 istiod.istio-system pod 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253$ kubectl -n istio-system delete svc istiod$ kubectl -n istio-system delete endpoints istiodcat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1kind: Servicemetadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | &#123;&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Service&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;app&quot;:&quot;istiod&quot;,&quot;install.operator.istio.io/owning-resource&quot;:&quot;unknown&quot;,&quot;install.operator.istio.io/owning-resource-namespace&quot;:&quot;istio-system&quot;,&quot;istio&quot;:&quot;pilot&quot;,&quot;istio.io/rev&quot;:&quot;default&quot;,&quot;operator.istio.io/component&quot;:&quot;Pilot&quot;,&quot;operator.istio.io/managed&quot;:&quot;Reconcile&quot;,&quot;operator.istio.io/version&quot;:&quot;1.8.4&quot;,&quot;release&quot;:&quot;istio&quot;&#125;,&quot;name&quot;:&quot;istiod&quot;,&quot;namespace&quot;:&quot;istio-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;ports&quot;:[&#123;&quot;name&quot;:&quot;grpc-xds&quot;,&quot;port&quot;:15010,&quot;protocol&quot;:&quot;TCP&quot;&#125;,&#123;&quot;name&quot;:&quot;https-dns&quot;,&quot;port&quot;:15012,&quot;protocol&quot;:&quot;TCP&quot;&#125;,&#123;&quot;name&quot;:&quot;https-webhook&quot;,&quot;port&quot;:443,&quot;protocol&quot;:&quot;TCP&quot;,&quot;targetPort&quot;:15017&#125;,&#123;&quot;name&quot;:&quot;http-monitoring&quot;,&quot;port&quot;:15014,&quot;protocol&quot;:&quot;TCP&quot;&#125;],&quot;selector&quot;:&#123;&quot;app&quot;:&quot;istiod&quot;,&quot;istio&quot;:&quot;pilot&quot;&#125;&#125;&#125; creationTimestamp: &quot;2021-03-22T07:08:32Z&quot; labels: app: istiod install.operator.istio.io/owning-resource: unknown install.operator.istio.io/owning-resource-namespace: istio-system istio: pilot istio.io/rev: default operator.istio.io/component: Pilot operator.istio.io/managed: Reconcile operator.istio.io/version: 1.8.4 release: istio name: istiod namespace: istio-system resourceVersion: &quot;826&quot; selfLink: /api/v1/namespaces/istio-system/services/istiod uid: 44ee44a6-9003-4f8d-9196-49e47b6667c1spec: clusterIP: 10.96.3.250 ports: - name: grpc-xds port: 15010 protocol: TCP targetPort: 15010 - name: https-dns port: 15012 protocol: TCP targetPort: 15012 - name: https-webhook port: 443 protocol: TCP targetPort: 15017 - name: http-monitoring port: 15014 protocol: TCP targetPort: 15014 selector: app: istiod istio: pilot sessionAffinity: None type: ClusterIPstatus: loadBalancer: &#123;&#125;EOF","categories":[],"tags":[]},{"title":"lxc","slug":"linux/lxc","date":"2021-03-16T14:29:22.000Z","updated":"2021-03-17T01:34:54.081Z","comments":true,"path":"2021/03/16/linux/lxc/","link":"","permalink":"http://example.com/2021/03/16/linux/lxc/","excerpt":"","text":"运行虚拟机时，容器几乎接近裸机。托管虚拟实例时，它们几乎没有开销。LXC于2008年首次引入，从其之前的Solaris Containers（或Solaris Zones）和FreeBSD jail中采用了其大部分功能。LXC无需创建完整的虚拟机，而是可以通过自己的进程和网络空间来实现虚拟环境。通过使用命名空间来强制执行进程隔离，并利用内核本身的控制组（cgroup）功能，该功能可以限制，说明和隔离一个或多个进程的CPU，内存，磁盘I / O和网络使用情况。将此用户空间框架视为的一种非常高级的形式 chroot。 注意：LXC使用名称空间来实现进程隔离，同时使用内核自己的cgroup来解决并限制一个或多个进程中的CPU，内存，磁盘I / O和网络使用情况。 但是容器到底是什么？简短的答案是，容器使软件应用程序与操作系统脱钩，从而为用户提供了一个干净而最小的Linux环境，同时在一个或多个隔离的“容器”中运行其他所有内容。容器的目的是启动一组有限的应用程序或服务（通常称为微服务），并使它们在独立的沙盒环境中运行。 这种隔离可防止在给定容器中运行的进程监视或影响在另一个容器中运行的进程。同样，这些容器化服务不会影响或干扰主机。能够将分散在多个物理服务器上的许多服务整合为一个的想法是数据中心选择采用该技术的众多原因之一。 容器功能包括： 安全性：网络服务可以在容器中运行，从而限制了由于安全漏洞或违反而造成的损害。入侵者成功利用该容器中运行的一个应用程序上的安全漏洞，仅限于该容器中可能采取的一系列操作。 隔离：容器允许在同一台物理计算机上部署一个或多个应用程序，即使这些应用程序必须在不同的域下运行，每个域都需要对其各自资源的独占访问权。例如，在不同容器中运行的多个应用程序可以通过使用与每个容器关联的不同IP地址绑定到同一物理网络接口。 虚拟化和透明性：容器为系统提供了虚拟化的环境，可以隐藏或限制其下的物理设备或系统配置的可见性。容器背后的一般原则是，除了解决安全性或隔离性问题之外，避免更改运行应用程序的环境。 Docker主要致力于： 可移植性：Docker提供了基于映像的部署模型。这种类型的可移植性提供了一种跨多个环境共享应用程序或服务集（及其所有依赖项）的简便方法。 版本控制：单个Docker映像由一系列组合的层组成。每当更改图像时，都会创建一个新层。例如，每次用户指定命令（例如run或）时 ，都会创建一个新层 copy。Docker将这些层重用于新的容器构建。与Docker分层是它自己的版本控制方法。 回滚：同样，每个Docker映像都有层。如果您不想使用当前运行的图层，则可以回滚到以前的版本。这种敏捷性使软件开发人员可以更轻松地连续集成和部署他们的软件技术。 快速部署：置备新硬件通常可能需要几天的时间。而且，安装和配置它的工作量和开销非常重。使用Docker，您可以通过将启动和运行映像所需的时间减少到几秒钟来避免所有这些情况。用完容器后，就可以轻松销毁它。 *** 从根本上说，Docker和LXC都非常相似。它们都是用户空间和轻量级虚拟化平台，它们实现cgroup和名称空间来管理资源隔离。但是，两者之间存在许多明显的差异。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"kernel","slug":"kernel","permalink":"http://example.com/tags/kernel/"}]},{"title":"route","slug":"linux/route","date":"2021-03-13T16:25:54.000Z","updated":"2021-03-18T03:42:58.321Z","comments":true,"path":"2021/03/14/linux/route/","link":"","permalink":"http://example.com/2021/03/14/linux/route/","excerpt":"","text":"","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}]},{"title":"Linux 虚拟网络设备详解之 Bridge 网桥","slug":"linux/bridge","date":"2021-03-13T14:44:26.000Z","updated":"2021-03-13T15:28:41.708Z","comments":true,"path":"2021/03/13/linux/bridge/","link":"","permalink":"http://example.com/2021/03/13/linux/bridge/","excerpt":"","text":"同 tap/tun、veth-pair 一样，Bridge 也是一种虚拟网络设备，所以具备虚拟网络设备的所有特性，比如可以配置 IP、MAC 等。 除此之外，Bridge 还是一个交换机，具有交换机所有的功能。 对于普通的网络设备，就像一个管道，只有两端，数据从一端进，从另一端出。而 Bridge 有多个端口，数据可以从多个端口进，从多个端口出。 Bridge 的这个特性让它可以接入其他的网络设备. 使用 来操作linux Bridge 安装 brctl1$ yum install bridge-utils -y 我们模拟一个docker0 类似的网桥 添加网桥(br0)123456789101112$ brctl addbr br0# 方法一:$ sudo ifconfig br0 192.168.100.1 netmask 255.255.255.0# 方法二:$ sudo ip addr add 192.168.100.0/16 dev bridge0$ sudo ip link set dev bridge0 up 2.查看网桥 1）显示所有的网桥信息 1$ sudo brctl show 2）显示某个网桥(br0)的信息 1$ sudo brctl show br0 3.删除网桥(br0) 1$ sudo brctl delbr br0 将eth0端口加入网桥br0 1$ brctl addif br0 eth0 从网桥br0中删除eth0端口 1$ brctl delif br0 eth0","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"network","slug":"network","permalink":"http://example.com/tags/network/"}]},{"title":"如何快速安装zsh","slug":"zsh","date":"2021-03-12T06:16:56.000Z","updated":"2021-03-12T06:18:54.283Z","comments":true,"path":"2021/03/12/zsh/","link":"","permalink":"http://example.com/2021/03/12/zsh/","excerpt":"","text":"Linux 安装并配置zsh1.1 安装zsh 1$ sudo apt-get install -y zsh 1.2 安装oh-my-zsh 1$ sh -c &quot;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot; 1.3 安装powerline font字体库 12$ sudo apt-get install fonts-powerline 1.4 打开zsh配置文件 ~/.zshrc，修改主题为agnoster 123451 # Set name of the theme to load --- if set to &quot;random&quot;, it will2 # load a random theme each time oh-my-zsh is loaded, in which case,3 # to know which specific one was loaded, run: echo $RANDOM_THEME4 # See https://github.com/ohmyzsh/ohmyzsh/wiki/Themes5 ZSH_THEME=&quot;agnoster&quot;","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}]},{"title":"如何快速安装k8s集群","slug":"k8s/install-k8s","date":"2021-03-12T05:13:13.000Z","updated":"2021-03-17T03:06:15.934Z","comments":true,"path":"2021/03/12/k8s/install-k8s/","link":"","permalink":"http://example.com/2021/03/12/k8s/install-k8s/","excerpt":"","text":"有时候需要快速搭建一个k8s集群帮组我测试代码的功能，这样可以帮我省去很多时间，把更多的时间都投入到写代码中，我觉得这也是很有必要的。接下来我就讲解如何快速搭建k8s集群。 首先准备若干个机器，这里我只是举例子 我现在准备了 三台机器 123456710.10.13.113 master10.10.13.114 node0110.10.13.115 node02 在ansible控制端配置免密码登录 1234567891011121314# 或者传统 RSA 算法$ ssh-keygen -t rsa -b 2048 -N &#x27;&#x27; -f ~/.ssh/id_rsa$ ssh-copy-id root@$IPs #$IPs为所有节点地址包括自身，按照提示输入yes 和root密码/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/Users/clare/.ssh/id_rsa.pub&quot;/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@xxx.xxx.xxx.xxx&#x27;s password:Number of key(s) added: 1Now try logging into the machine, with: &quot;ssh &#x27;root@xxx.xxx.xxx.xxx&#x27;&quot;and check to make sure that only the key(s) you wanted were added. 1234# 测试是否可以免密登陆$ ssh root@$IPs 3.1 安装ansible (也可以使用容器化运行kubeasz，已经预装好ansible) 123456789# 注意pip 21.0以后不再支持python2和python3.5，需要如下安装# To install pip for Python 2.7 install it from https://bootstrap.pypa.io/2.7/ :curl -O https://bootstrap.pypa.io/2.7/get-pip.pypython get-pip.pypython -m pip install --upgrade &quot;pip &lt; 21.0&quot;# pip安装ansible(国内如果安装太慢可以直接用pip阿里云加速)pip install ansible -i https://mirrors.aliyun.com/pypi/simple/ 下载工具脚本ezdown1234567891011121314# 下载工具脚本ezdown，举例使用kubeasz版本3.0.0$ export release=3.0.0$ curl -C- -fLO --retry 3 https://github.com/easzlab/kubeasz/releases/download/$&#123;release&#125;/ezdown$ chmod +x ./ezdown# 使用工具脚本下载$ chmod +x ezdown# 下载安装包# k 指定kubernetes的版本$ ./ezdown -D -k v1.18.3 4.2 创建集群配置实例 12345678ezctl new k8s-012021-01-19 10:48:23 DEBUG generate custom cluster files in /etc/kubeasz/clusters/k8s-012021-01-19 10:48:23 DEBUG set version of common plugins2021-01-19 10:48:23 DEBUG cluster k8s-01: files successfully created.2021-01-19 10:48:23 INFO next steps 1: to config &#x27;/etc/kubeasz/clusters/k8s-01/hosts&#x27;2021-01-19 10:48:23 INFO next steps 2: to config &#x27;/etc/kubeasz/clusters/k8s-01/config.yml&#x27;然后根据提示配置&#x27;/etc/kubeasz/clusters/k8s-01/hosts&#x27; 和 &#x27;/etc/kubeasz/clusters/k8s-01/config.yml&#x27;: 根据前面节点规划修改hosts 文件和其他集群层面的主要配置选项；其他集群组件等配置项可以在config.yml 文件中修改。 4.3 开始安装 如果你对集群安装流程不熟悉，请阅读项目首页 安装步骤 讲解后分步安装，并对 每步都进行验证 一键安装1234567$ ezctl setup k8s-01 all# 或者分步安装，具体使用 ezctl help setup 查看分步安装帮助信息# ezctl setup k8s-01 01# ezctl setup k8s-01 02# ezctl setup k8s-01 03# ezctl setup k8s-01 04","categories":[],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://example.com/tags/kubernetes/"}]},{"title":"cgroups Linux控制组","slug":"linux/cgroups","date":"2021-03-10T10:06:35.000Z","updated":"2021-03-11T08:33:36.010Z","comments":true,"path":"2021/03/10/linux/cgroups/","link":"","permalink":"http://example.com/2021/03/10/linux/cgroups/","excerpt":"","text":"实话实说,某些软件应用程序可能需要控制或限制-至少出于稳定性和某种程度上的安全性考虑。错误或错误代码常常会破坏整个计算机,并可能破坏整个生态系统。幸运的是,有一种方法可以检查那些相同的应用程序。控制组（cgroups）是一项内核功能,可以限制,说明和隔离一个或多个进程的CPU,内存,磁盘I / O和网络使用情况。 cgroups框架提供以下内容： 资源限制： 可以将组配置为不超过指定的内存限制或使用的处理器数量不超过期望的数量,或者限制为特定的外围设备。优先级： 可以将一个或多个组配置为利用更少或更多的CPU或磁盘 I/O 吞吐量。监控： 监视和衡量组的资源使用情况。控制： 可以冻结或停止并重新启动一组进程。 一个cgroup可以包含一个或多个绑定到同一组限制的进程。这些组也可以是分层的,这意味着子组继承了对其父组管理的限制。 Linux内核提供对cgroup技术的一系列控制器或子系统的访问。控制器负责将特定类型的系统资源分配给一组一个或多个进程。例如,memory控制器是在cpuacct监视CPU使用率时限制内存使用率的。 您可以直接和间接（使用LXC,libvirt或Docker）访问和管理cgroup,在此我将首先通过sysfs和libcgroups库来介绍和管理cgroup 。要遵循此处的示例,您首先需要安装必要的软件包。在Red Hat Enterprise Linux或CentOS上,在命令行上键入以下内容： 123456789101112blkio：设置限制每个块设备的输入输出控制。例如:磁盘，光盘以及usb等等。cpu：使用调度程序为cgroup任务提供cpu的访问。cpuacct：产生cgroup任务的cpu资源报告。cpuset：如果是多核心的cpu，这个子系统会为cgroup任务分配单独的cpu和内存。devices：允许或拒绝cgroup任务对设备的访问。freezer：暂停和恢复cgroup任务。memory：设置每个cgroup的内存限制以及产生内存资源报告。net_cls：标记每个网络包以供cgroup方便使用。ns：命名空间子系统。perf_event：增加了对每group的监测跟踪的能力，即可以监测属于某个特定的group的所有线程以及运行在特定CPU上的线程。 cgroups 对内存的限制手动方式安装了正确的软件包后，您可以直接通过sysfs层次结构配置cgroup。例如，要foo在memory子系统下创建一个名为cgroup 的目录，请在/ sys / fs / cgroup / memory中创建一个名为foo的目录： 1$ sudo mkdir /sys/fs/cgroup/memory/foo 默认情况下，每个新创建的cgroup都将继承对系统整个内存池的访问权限。对于某些应用程序，主要是那些继续分配更多内存但拒绝释放已经分配的内存的应用程序，可能不是一个好主意。要将应用程序限制在合理的范围内，您需要更新 memory.limit_in_bytes文件。 将在cgroup下运行的任何内容的内存限制foo为50MB： 1$ echo 50000000 | sudo tee /sys/fs/cgroup/memory/foo/memory.limit_in_bytes 验证设置： 12$ sudo cat memory.limit_in_bytes50003968 请注意，回读的值始终是内核页面大小的倍数（即4096字节或4KB）。该值是最小的可分配内存大小。 启动应用程序： 1$ sh ~/test.sh &amp; 使用其进程ID（PID），将应用程序移动到控制器foo下的 cgroup memory： 1$ echo 2845 &gt; /sys/fs/cgroup/memory/foo/cgroup.procs 使用相同的PID编号，列出正在运行的进程并验证其是否在所需的cgroup中运行： 123$ ps -o cgroup 2845CGROUP8:memory:/foo,1:name=systemd:/user.slice/user-0.slice/session-4.scope 您还可以通过读取所需的文件来监视该cgroup当前正在使用的内容。在这种情况下，您将需要查看由您的进程（和产生的子进程）分配的内存量： 12$ cat /sys/fs/cgroup/memory/foo/memory.usage_in_bytes253952 当我改变limit现在，让我们重新创建相同的场景，但不要将cgroup限制 foo为50MB内存，而是将其限制为500个字节： 1$ echo 500 | sudo tee /sys/fs/cgroup/memory/foo/memory.limit_in_bytes 注意：如果一项任务超出其定义的限制，内核将进行干预，在某些情况下，将终止该任务。 同样，当您读回该值时，该值将始终是内核页面大小的倍数。因此，尽管将其设置为500字节，但实际上设置为4 KB： 12$ cat /sys/fs/cgroup/memory/foo/memory.limit_in_bytes4096 启动应用程序，将其移至cgroup并监视系统日志： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465$ sudo tail -f /var/log/messagesOct 14 10:22:40 localhost kernel: sh invoked oom-killer:↪gfp_mask=0xd0, order=0, oom_score_adj=0Oct 14 10:22:40 localhost kernel: sh cpuset=/ mems_allowed=0Oct 14 10:22:40 localhost kernel: CPU: 0 PID: 2687 Comm:↪sh Tainted: GOE ------------ 3.10.0-327.36.3.el7.x86_64 #1Oct 14 10:22:40 localhost kernel: Hardware name: innotek GmbHVirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006Oct 14 10:22:40 localhost kernel: ffff880036ea5c00↪0000000093314010 ffff88000002bcd0 ffffffff81636431Oct 14 10:22:40 localhost kernel: ffff88000002bd60↪ffffffff816313cc 01018800000000d0 ffff88000002bd68Oct 14 10:22:40 localhost kernel: ffffffffbc35e040↪fffeefff00000000 0000000000000001 ffff880036ea6103Oct 14 10:22:40 localhost kernel: Call Trace:Oct 14 10:22:40 localhost kernel: [&lt;ffffffff81636431&gt;]↪dump_stack+0x19/0x1bOct 14 10:22:40 localhost kernel: [&lt;ffffffff816313cc&gt;]↪dump_header+0x8e/0x214Oct 14 10:22:40 localhost kernel: [&lt;ffffffff8116d21e&gt;]↪oom_kill_process+0x24e/0x3b0Oct 14 10:22:40 localhost kernel: [&lt;ffffffff81088e4e&gt;] ?↪has_capability_noaudit+0x1e/0x30Oct 14 10:22:40 localhost kernel: [&lt;ffffffff811d4285&gt;]↪mem_cgroup_oom_synchronize+0x575/0x5a0Oct 14 10:22:40 localhost kernel: [&lt;ffffffff811d3650&gt;] ?↪mem_cgroup_charge_common+0xc0/0xc0Oct 14 10:22:40 localhost kernel: [&lt;ffffffff8116da94&gt;]↪pagefault_out_of_memory+0x14/0x90Oct 14 10:22:40 localhost kernel: [&lt;ffffffff8162f815&gt;]↪mm_fault_error+0x68/0x12bOct 14 10:22:40 localhost kernel: [&lt;ffffffff816422d2&gt;]↪__do_page_fault+0x3e2/0x450Oct 14 10:22:40 localhost kernel: [&lt;ffffffff81642363&gt;]↪do_page_fault+0x23/0x80Oct 14 10:22:40 localhost kernel: [&lt;ffffffff8163e648&gt;]↪page_fault+0x28/0x30Oct 14 10:22:40 localhost kernel: Task in /foo killed as↪a result of limit of /fooOct 14 10:22:40 localhost kernel: memory: usage 4kB, limit↪4kB, failcnt 8Oct 14 10:22:40 localhost kernel: memory+swap: usage 4kB,↪limit 9007199254740991kB, failcnt 0Oct 14 10:22:40 localhost kernel: kmem: usage 0kB, limit↪9007199254740991kB, failcnt 0Oct 14 10:22:40 localhost kernel: Memory cgroup stats for /foo:↪cache:0KB rss:4KB rss_huge:0KB mapped_file:0KB swap:0KB↪inactive_anon:0KB active_anon:0KB inactive_file:0KB↪active_file:0KB unevictable:0KBOct 14 10:22:40 localhost kernel: [ pid ] uid tgid total_vm↪rss nr_ptes swapents oom_score_adj nameOct 14 10:22:40 localhost kernel: [ 2687] 0 2687 28281↪347 12 0 0 shOct 14 10:22:40 localhost kernel: [ 2702] 0 2702 28281↪50 7 0 0 shOct 14 10:22:40 localhost kernel: Memory cgroup out of memory:↪Kill process 2687 (sh) score 0 or sacrifice childOct 14 10:22:40 localhost kernel: Killed process 2702 (sh)↪total-vm:113124kB, anon-rss:200kB, file-rss:0kBOct 14 10:22:41 localhost kernel: sh invoked oom-killer:↪gfp_mask=0xd0, order=0, oom_score_adj=0[ ... ] 请注意，一旦应用程序达到4KB的限制，内核的“内存不足杀手”（或oom-killer）就会介入。它终止了该应用程序，并且不再运行。您可以通过键入以下内容进行验证： 1234$ ps -o cgroup 2687CGROUP 使用libcgrouplibcgroup软件包中 提供的管理实用程序简化了此处描述的许多早期步骤。例如，使用cgcreate二进制文件的单个命令调用将负责创建sysfs条目和文件的过程。 要创建在 子系统foo下命名的组memory，请键入以下内容： 1$ sudo cgcreate -g memory:foo 注意：libcgroup提供了一种用于管理控制组中的任务的机制。 使用与以前相同的方法，您可以开始设置阈值： 12$ echo 50000000 | sudo tee↪/sys/fs/cgroup/memory/foo/memory.limit_in_bytes 验证新配置的设置： 12$ sudo cat memory.limit_in_bytes50003968 foo使用 cgexec二进制文件 在cgroup中运行应用程序： 1$ sudo cgexec -g memory:foo ~/test.sh 使用其PID编号，验证应用程序正在cgroup中并在已定义的子系统（memory）下运行： 1234$ ps -o cgroup 2945CGROUP6:memory:/foo,1:name=systemd:/user.slice/user-0.slice/↪session-1.scope 如果您的应用程序不再运行，并且您想要清理并删除cgroup，则可以使用cgdelete二进制文件来完成。要从控制器foo 下面删除组memory，请键入： 1$ sudo cgdelete memory:foo 持久群体您还可以通过一个简单的配置文件和启动服务来完成上述所有操作。您可以在/etc/cgconfig.conf文件中定义所有cgroup名称和属性。以下内容为该组添加了一些属性foo： 123456789101112131415161718192021222324252627282930$ cat /etc/cgconfig.conf## Copyright IBM Corporation. 2007## Authors: Balbir Singh &lt;balbir@linux.vnet.ibm.com&gt;# This program is free software; you can redistribute it# and/or modify it under the terms of version 2.1 of the GNU# Lesser General Public License as published by the Free# Software Foundation.## This program is distributed in the hope that it would be# useful, but WITHOUT ANY WARRANTY; without even the implied# warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR# PURPOSE.### By default, we expect systemd mounts everything on boot,# so there is not much to do.# See man cgconfig.conf for further details, how to create# groups on system boot using this file.group foo &#123;cpu &#123;cpu.shares = 100;&#125;memory &#123;memory.limit_in_bytes = 5000000;&#125;&#125; 这些cpu.shares选项定义组的CPU优先级。默认情况下，所有组都继承1,024个份额或100％的CPU时间。通过将此值降低到较为保守的程度（例如100），该组将被限制为大约CPU时间的10％。 如前所述，在cgroup中运行的进程也可以限制为它可以访问的CPU（核心）数量。将以下部分添加到相同的cgconfig.conf文件中，并在所需的组名称下： 12345cpuset &#123;cpuset.cpus=&quot;0-5&quot;;&#125; 有了这个限制，此cgroup会将应用程序绑定到核心0到5-也就是说，它将仅看到系统上的前六个CPU核心。 接下来，您需要使用该cgconfig服务加载此配置。首先，启用cgconfig以在系统启动时加载以上配置： 1234$ sudo systemctl enable cgconfigCreate symlink from /etc/systemd/system/sysinit.target.wants/↪cgconfig.serviceto /usr/lib/systemd/system/cgconfig.service. 现在，启动cgconfig服务并手动加载相同的配置文件（或者您可以跳过此步骤并重新引导系统）： 1$ sudo systemctl start cgconfig 将应用程序启动到cgroup中，foo并将其绑定到您的 memory和cpu 限制： 1$ sudo cgexec -g memory,cpu,cpuset:foo ~/test.sh &amp; 除了将应用程序启动到预定义的cgroup中之外，其余所有内容将在系统重新引导后继续存在。但是，您可以通过定义依赖于cgconfig 服务的启动初始化脚本来启动该应用程序，从而自动执行该过程 。","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"kernal","slug":"kernal","permalink":"http://example.com/tags/kernal/"}]},{"title":"Linux 命名空间概述","slug":"linux/namespace","date":"2021-03-10T09:12:47.000Z","updated":"2021-03-18T02:06:09.495Z","comments":true,"path":"2021/03/10/linux/namespace/","link":"","permalink":"http://example.com/2021/03/10/linux/namespace/","excerpt":"","text":"namespace 的概念namespace 是 Linux 内核用来隔离内核资源的方式。通过 namespace 可以让一些进程只能看到与自己相关的一部分资源，而另外一些进程也只能看到与它们自己相关的资源，这两拨进程根本就感觉不到对方的存在。具体的实现方式是把一个或多个进程的相关资源指定在同一个 namespace 中。 namespace 的比喻对于某些人来说，namespace这个定义有很多不能让人理解的地方，因此以下这种比方可能会对你有所帮助。考虑一下我的公寓楼。从技术上讲，这是两座不同的建筑，都有自己的入口。但是，停车场，健身房，游泳池和公共休息室是共享的。这些建筑物有自己的名称，城市广场和城市广场2。他们有自己的街道地址，楼层和电梯。然而，它们依附于相同的物理复合体。 物理复合体与计算机的想法相同。两个名称空间（或多个名称空间）可以驻留在同一台物理计算机上，并且与公寓楼一样，名称空间可以共享对某些资源的访问权限，也可以具有独占访问权限。 今天，有七种常见的名称空间被广泛使用。以公寓为指导，让我们逐步总结每种类型的功能。下面是每种名称空间类型的简要概述。在后续文章中，我们将通过示例展示每个命名空间的工作方式。 namespace 的类型有哪些 进程隔离（PID名称空间） 网络接口（网络名称空间） Unix时间共享系统（uts名称空间） 用户名称空间 挂载（mnt名称空间） 进程间通信（IPC） CGroups linux 网络命名空间 ip netns add xx 建立一個 namespace 123$ ip netns add net1$ ip netns lsnet1 ip netns exec 在新 namespace net1 中執行 BASH SHELL 命令 12345$ ip netns exec net1 bash# exit 退出容器空间$ exit 每個 namespace 在建立的時候會自動建立一個迴環介面 lo ，預設不啟用，可以通過 啟用。 1$ ip link set lo up network namespace 之間的通訊新建立的 namespace 預設不能和主機網路，以及其他 namespace 通訊。 可以使用 Linux 提供的 veth pair 來完成通訊。下面顯示兩個 namespace 之间的网络拓扑图： 3.1 ip link add type veth 建立 veth pair 123456789101112# 查看veth$ ip link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether 00:50:56:a9:e9:17 brd ff:ff:ff:ff:ff:ff3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default link/ether 02:42:8b:f3:61:ac brd ff:ff:ff:ff:ff:ff 添加 link veth pair 123456789101112131415161718192021222324# 添加 veth pair$ ip link add type veth# 使用命令 ip link add xxx type veth peer name yyy 指定 veth pair 的名字。$ ip link add veth1 type veth peer name veth2$ ip link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether 00:50:56:a9:e9:17 brd ff:ff:ff:ff:ff:ff3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default link/ether 02:42:8b:f3:61:ac brd ff:ff:ff:ff:ff:ff8: veth2@veth1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 6e:86:2f:10:5c:50 brd ff:ff:ff:ff:ff:ff9: veth1@veth2: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 0a:b8:54:5b:9f:7d brd ff:ff:ff:ff:ff:ff veth pair 因为是成对出现的 所以 有8和9 分别是`veth1@veth2` -- `veth2@veth1` 3.2 ip link set xx netns yy 將 veth xx 加入到 namespace yy 中 1234$ ip link set veth1 netns net1$ ip link set veth2 netns net2 加入到namespace 有以下现象 1234567891011121314151617181920$ ip link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether 00:50:56:a9:e9:17 brd ff:ff:ff:ff:ff:ff3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default link/ether 02:42:8b:f3:61:ac brd ff:ff:ff:ff:ff:ff8: veth2@if9: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 6e:86:2f:10:5c:50 brd ff:ff:ff:ff:ff:ff link-netnsid 0 $ ip link set veth2 netns net2$ ip link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether 00:50:56:a9:e9:17 brd ff:ff:ff:ff:ff:ff3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default link/ether 02:42:8b:f3:61:ac brd ff:ff:ff:ff:ff:ff 3.3 給 veth pair 配上 ip 地址 12345678910111213# 给net0 namespace 空间 veth0 up$ ip netns exec net1 ip link set veth1 up$ ip addr add 10.1.1.1/24 dev veth1# veth0 up 设置ip 启动起来$ ip route10.1.1.0/24 dev veth1 proto kernel scope link src 10.1.1.1# 给net2 namespace 空间 veth2 up$ ip addr add 10.1.1.2/24 dev veth2","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"kernal","slug":"kernal","permalink":"http://example.com/tags/kernal/"}]},{"title":"iptables 详解","slug":"analysis","date":"2021-03-09T11:03:03.000Z","updated":"2021-03-09T13:51:26.310Z","comments":true,"path":"2021/03/09/analysis/","link":"","permalink":"http://example.com/2021/03/09/analysis/","excerpt":"","text":"iptables 详解iptables其实不是真正的防火墙，我们可以把它理解成一个客户端代理，用户通过iptables这个代理，将用户的安全设定执行到对应的”安全框架”中，这个”安全框架”才是真正的防火墙，这个框架的名字叫netfilter netfilter才是防火墙真正的安全框架（framework），netfilter位于内核空间。 iptables其实是一个命令行工具，位于用户空间，我们用这个工具操作真正的框架。 iptables 的表（tables） 和链（chains）描述完iptables术语后、相信大家对iptables的表和链有了初步的了解了、默认情况下。Iptables，根据功能和表的定义划分、最常用的有三个表，分别是filter,nat mangle.其中每个表又有各自包含不同的操作链（chains） 处理动作处理动作在iptables中被称为target（这样说并不准确，我们暂且这样称呼），动作也可以分为基本动作和扩展动作。 此处列出一些常用的动作，之后的文章会对它们进行详细的示例与总结： ACCEPT：允许数据包通过。 DROP：直接丢弃数据包，不给任何回应信息，这时候客户端会感觉自己的请求泥牛入海了，过了超时时间才会有反应。 REJECT：拒绝数据包通过，必要时会给数据发送端一个响应的信息，客户端刚请求就会收到拒绝的信息。 SNAT：源地址转换，解决内网用户用同一个公网地址上网的问题。 MASQUERADE：是SNAT的一种特殊形式，适用于动态的、临时会变的ip上。 DNAT：目标地址转换。 REDIRECT：在本机做端口映射。 LOG：在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则，也就是说除了记录以外不对数据包做任何其他操作，仍然让下一条规则去匹配。 iptables具有以下4个内置表1. Filter1234567891011Filter表和主机自身相关、负责防火墙（过滤本机流入、流出数据包）。是iptables默认使用的表、这个表定义了三个链（chains）说明如下INPUT 负责过滤所有目标地址是主机（防火墙）地址的数据包、通俗的讲、就是过滤进入主机的数据包。FORWARD 负责转发流经主机但不进入本机的数据包、起转发作用、和NAT表关系很大、后面会详细介绍OUTPUT 处理所有原地址是本机地址的数据包、通俗的讲就是处理从主机发出去的数据包。 2. NAT表123456789101112131415NAT表是网络地址转换的意思。即负责来源与目的IP地址和port的转换、和主机本身无关。一般用于局域网多人共享上网或者内网IP映射外网IP及不同端口转换服务等功能。Nat表的功能很重要、这个表定义了三个链（chains）OUTPUT主机发出去的数据包有关、在数据包路由之前改变主机产生的数据包的目的地址等。PREROUTING在数据包刚到达防火墙时、进行路由判断之前执行的规则、改变包的目的地址（DNAT功能）、端口等（通俗比喻，就是收信时、根据规则重写收件人的地址、这看上去不地道啊、）把公司IP映射到局域网的机器上、此链多用于把外部IP地址端口的服务、映射为内部IP地址及端口POSTROUTING在数据包离开防火墙时进行路由判断之后执行的规则、改变包的源地址（SNAT）、端口等（通俗比喻、就是寄信时写好发件人的地址、要让人家回信是能够有地址可回）刺链多用于局域网共享上网，把所有局域网的地址、转换为公网地址上 3. Mangle123456789101112131415161718Mangle主要负责修改数据包中特殊的路由标记，如TTL、TOS、MARK等、这个表定义了5个链（chains）INPUT同filter表的INPUTFORWARD同filter表的FORWARDOUTPUT 同fileter表的OUTPUTPREROUTING 同nat表的PREROUTINGPOSTOUTING 同nat表的POSTOUTING 4. Raw12 后面在说 参数定义123456789101112131415161718192021222324252627282930313233343536373839-t：指定要操纵的表； `table`-A：向规则链中添加条目；`Append`-D：从规则链中删除条目； `delete`-I：向规则链中插入条目；`insert`-R：替换规则链中的条目；`replace`-L：显示规则链中已有的条目；``-F：清除规则链中已有的条目；`flush`-Z：清空规则链中的数据包计算器和字节计数器；-N：创建新的用户自定义规则链；-P：定义规则链中的默认目标；`policy`-h：显示帮助信息；`help`-p：指定要匹配的数据包协议类型；`proto protocol: by number or name, eg. tcp`-s：指定要匹配的数据包源ip地址；`source`-d：指定要匹配的数据包目标ip地址；`destination`-j：指定要跳转的目标；`jump`-i：指定数据包进入本机的网络接口（网卡）；`input`-o：指定数据包离开本机的网络接口（网卡）；`onput`--sport：匹配来源端口号；`source port`--dport：匹配目标端口号。`destination port`下述规则允许端口80上的传入HTTP通信。 例如123$ iptables -A INPUT -i eth1 -p tcp --dport 80 -d 1.2.3.4 -j ACCEPT -A 表示我们正在添加新规则。缺省情况下，除非您指定另一个表，否则iptables会将所有新规则添加到 Filter 表中。 -i 标志指定将规则应用到的设备。如果您未指定设备，则iptables会将规则应用于所有传入流量，而与设备无关。 -p 标志指定要处理的数据包协议，在本例中为TCP。 –dport 标志指定目标端口，该端口为80。 -d 指定目标IP地址，即1.2.3.4。如果未指定目标IP地址，则该规则将适用于eth1上的所有传入流量，而不管IP地址如何。 -j 指定要执行的操作或JUMP操作。在这里，我们使用接受策略来接受数据包。 开放端口指定插入第几行 123456# --line-number 展示行号$ iptables -nL --line-number# 在第四行插入iptables$ iptables -I INPUT 4 -p tcp --dport 1234 -j ACCEPT 禁止所有INPUT 12$ iptables -P INPUT DROP$ iptables -P OUTPUT DROP 我现在用一个测试软件来测试连通性 四、nc搭建简单内网聊天室本机-本机 ， 单台机器开了两个shell窗口，当一个窗口输入消息时，另一个窗口也会同步显示 1ncat -v -lp 8080 服务端12345678[root@localhost ~]$ ncat -v -lp 8080Ncat: Version 7.50 ( https://nmap.org/ncat )Ncat: Listening on :::8080Ncat: Listening on 0.0.0.0:8080Ncat: Connection from 127.0.0.1.Ncat: Connection from 127.0.0.1:45996.xxxxxx 客户端12345[root@localhost ~]$ nc -v 127.0.0.1 8080Ncat: Version 7.50 ( https://nmap.org/ncat )Ncat: Connected to 127.0.0.1:8080.xxxxxx NAT 作用及使用我们现在讲一下nat表主要的作用 端口转发 1234567891011121314# 将 8080 转发到80 端口上面 $ iptables -t nat -A PREROUTING -p tcp --dport 8080 -j REDERECT --to-ports 8000# 如果防火墙默认是关闭的状态则需要设置以下规则$ iptables -A INPUT -p tcp --dport 8000 -j ACCEPT$ iptables -A OUTPUT -p tcp --sport 8000 -j ACCEPT 流量转发将流量转发到服务器上面在 10.10.13.111 上 设置 将 对 10.10.13.111的请求转发到10.10.13.110 并实现 逆转, 123iptables -t nat -I PREROUTING -p tcp --dport 8001 -d 10.10.13.111 -j DNAT --to-destination 10.10.13.110iptables -t nat -I POSTROUTING -p tcp --dport 8001 -d 10.10.13.110 -j SNAT --to-destination 10.10.13.111","categories":[],"tags":[{"name":"iptables","slug":"iptables","permalink":"http://example.com/tags/iptables/"}]},{"title":"kiali 源码解析","slug":"k8s/kiali","date":"2021-01-21T10:36:28.000Z","updated":"2021-03-09T14:29:31.898Z","comments":true,"path":"2021/01/21/k8s/kiali/","link":"","permalink":"http://example.com/2021/01/21/k8s/kiali/","excerpt":"","text":"kiali 源码解析 前言: Kiali是用于基于Istio的服务网格的管理控制台。它提供仪表板，可观察性，并允许您使用强大的配置和验证功能来操作网格。它通过推断流量拓扑来显示服务网格的结构，并显示网格的运行状况。Kiali提供了详细的指标，强大的验证，Grafana访问以及与Jaeger进行分布式跟踪的强大集成。 以下就是kiali的流量试图 界面 Kiali是用于基于Istio的服务网格的管理控制台 所以得使用istio来安装kiali插件 如何istio 来安装kiali 1$ istioctl manifest apply --set values.kiali.enabled=true kiali 的默认 用户名与密码是 admin/admin kiali 流量试图kiali route 路由routing/router 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 根路由 指向 静态页面if webRoot != &quot;/&quot; &#123; rootRouter.HandleFunc(webRoot, func(w http.ResponseWriter, r *http.Request) &#123; http.Redirect(w, r, webRootWithSlash, http.StatusFound) &#125;) // help the user out - if a request comes in for &quot;/&quot;, redirect to our true webroot rootRouter.HandleFunc(&quot;/&quot;, func(w http.ResponseWriter, r *http.Request) &#123; http.Redirect(w, r, webRootWithSlash, http.StatusFound) &#125;) appRouter = rootRouter.PathPrefix(conf.Server.WebRoot).Subrouter() &#125; appRouter = appRouter.StrictSlash(true)// 路由指向代理的function r.Routes = []Route&#123; // swagger:route GET /healthz kiali healthz // --- // Endpoint to get the health of Kiali // // Produces: // - application/json // // Schemes: http, https // responses: // 500: internalError // 200 &#123; &quot;Healthz&quot;, &quot;GET&quot;, &quot;/healthz&quot;, handlers.Healthz, false, &#125;, // swagger:route GET / kiali root // --- // Endpoint to get the status of Kiali // // Produces: // - application/json // // Schemes: http, https // responses: // 500: internalError // 200: statusInfo &#123; &quot;Root&quot;, &quot;GET&quot;, &quot;/api&quot;, handlers.Root, false, &#125;&#125; kiali里面最复杂的就是流量视图了 现在我们看看kiali是怎么做的 /graph/api/api 123456789101112131415161718192021func GraphNamespaces(business *business.Layer, o graph.Options) (code int, config interface&#123;&#125;) &#123; // time how long it takes to generate this graph promtimer := internalmetrics.GetGraphGenerationTimePrometheusTimer(o.GetGraphKind(), o.TelemetryOptions.GraphType, o.InjectServiceNodes) defer promtimer.ObserveDuration() switch o.TelemetryVendor &#123; case graph.VendorIstio: prom, err := prometheus.NewClientNoAuth(business.PromAddress) graph.CheckError(err)//获取config 蓝图信息 code, config = graphNamespacesIstio(business, prom, o) default: graph.Error(fmt.Sprintf(&quot;TelemetryVendor [%s] not supported&quot;, o.TelemetryVendor)) &#125; // update metrics internalmetrics.SetGraphNodes(o.GetGraphKind(), o.TelemetryOptions.GraphType, o.InjectServiceNodes, 0) return code, config&#125; 构造 TrafficMap graph/telemetry/istio/istio.go 123456789101112131415161718192021222324252627282930313233343536// BuildNamespacesTrafficMap is required by the graph/TelemtryVendor interfacefunc BuildNamespacesTrafficMap(o graph.TelemetryOptions, client *prometheus.Client, globalInfo *graph.AppenderGlobalInfo) graph.TrafficMap &#123; log.Tracef(&quot;Build [%s] graph for [%v] namespaces [%s]&quot;, o.GraphType, len(o.Namespaces), o.Namespaces) setLabels() appenders := appender.ParseAppenders(o) trafficMap := graph.NewTrafficMap() for _, namespace := range o.Namespaces &#123; log.Tracef(&quot;Build traffic map for namespace [%s]&quot;, namespace) //生成一个 namespaceTrafficMap namespaceTrafficMap := buildNamespaceTrafficMap(namespace.Name, o, client) namespaceInfo := graph.NewAppenderNamespaceInfo(namespace.Name) for _, a := range appenders &#123; appenderTimer := internalmetrics.GetGraphAppenderTimePrometheusTimer(a.Name()) a.AppendGraph(namespaceTrafficMap, globalInfo, namespaceInfo) appenderTimer.ObserveDuration() &#125; // 将 namespaceTrafficMap merge ----&gt; trafficMap 中 telemetry.MergeTrafficMaps(trafficMap, namespace.Name, namespaceTrafficMap) &#125; // The appenders can add/remove/alter nodes. After the manipulations are complete // we can make some final adjustments: // - mark the outsiders (i.e. nodes not in the requested namespaces) // - mark the insider traffic generators (i.e. inside the namespace and only outgoing edges) telemetry.MarkOutsideOrInaccessible(trafficMap, o) telemetry.MarkTrafficGenerators(trafficMap) if graph.GraphTypeService == o.GraphType &#123; trafficMap = telemetry.ReduceToServiceGraph(trafficMap) &#125; return trafficMap&#125; Appender 这个interface 主要负责获取和组装流量视图的节点信息和线的信息 graph/appender.go 1234567891011// Appender is implemented by any code offering to append a service graph with// supplemental information. On error the appender should panic and it will be// handled as an error response.type Appender interface &#123; // AppendGraph performs the appender work on the provided traffic map. The map // may be initially empty. An appender is allowed to add or remove map entries. AppendGraph(trafficMap TrafficMap, globalInfo *AppenderGlobalInfo, namespaceInfo *AppenderNamespaceInfo) // Name returns a unique appender name and which is the name used to identify the appender (e.g in &#x27;appenders&#x27; query param) Name() string&#125; appender中有几种实现 istio: 负责标记具有特殊Istio意义的节点 deadNode: 负责从图中删除不需要的节点 serviceEntry: ServiceEntryAppender负责标识在Istio中定义为serviceEntry的服务节点。单个serviceEntry可以定义多个主机，因此多个服务节点可以映射到单个serviceEntry的不同主机。我们将这些称为“ se-service”节点 responseTime: ResponseTimeAppender负责将responseTime信息添加到图形中 securityPolicy: SecurityPolicyAppender负责向图表添加securityPolicy信息。尽管以通用方式编写，但该附加程序当前仅报告international_tls安全性。 sidecarsCheck: SidecarsCheckAppender标记其后备工作负载缺少至少一个Envoy sidecar的节点。请注意，没有后备工作负载的节点未标记。 unusedNode: 调用函数成功时，函数处理时间指标的持续时间值。如果不成功，则递增失败计数器。如果围棋函数不在一个类型上（即是一个全局函数），请为goType传入一个空字符串。当该函数返回时，定时器立即开始计时。 appender中的实现必须得有先后顺序, service-entry –&gt; deadNode –&gt; responseTime —&gt; securityPolicy —&gt; unusedNode –&gt; istio 经过appender之后将trafficMap merge 到 traffic map中 12345trafficMap := graph.NewTrafficMap()// 将 namespaceTrafficMap merge ----&gt; trafficMap 中telemetry.MergeTrafficMaps(trafficMap, namespace.Name, namespaceTrafficMap)","categories":[{"name":"istio","slug":"istio","permalink":"http://example.com/categories/istio/"}],"tags":[{"name":"kiali","slug":"kiali","permalink":"http://example.com/tags/kiali/"},{"name":"istio","slug":"istio","permalink":"http://example.com/tags/istio/"}]},{"title":"istio 流量管理使用说明","slug":"k8s/istio-use","date":"2021-01-20T16:00:00.000Z","updated":"2021-03-09T14:29:13.300Z","comments":true,"path":"2021/01/21/k8s/istio-use/","link":"","permalink":"http://example.com/2021/01/21/k8s/istio-use/","excerpt":"","text":"istio 流量管理使用说明 前提条件在开始之前，请检查以下先决条件： 检查kubernetes 集群pod和 服务 使用1.6 以上版本的istio,并检查 pod和服务 设定 必要的平台设置 部署测试服务 bookinfo我们就使用istio 官方使用的测试服务BookInfo Bookinfo应用程序分为四个单独的微服务： productpage。该productpage微服务调用details和reviews微服务来填充页面。details。该details微服务包含图书信息。reviews。该reviews微服务包含了书评。它还称为ratings微服务。ratings。该ratings微服务包含预定伴随书评排名信息。reviews微服务有3个版本： 版本v1不会调用该ratings服务。版本v2调用该ratings服务，并将每个等级显示为1到5个黑星。版本v3调用该ratings服务，并将每个等级显示为1到5个红色星号。 访问关系如下图 首先部署bookinfo服务之前我们需要给 bookinfo 注入sidecar,若给namespace打 istio-injection=enabled的labels 则istio会给当前namespace下的所有pod自动注入sidecar 假设我们将bookinfo 部署到demo的这个namespace中 12$ kubectl label namespace demo istio-injection=enabled 查看labels是否设置成功 1$ kubectl get namespace demo --show-labels 然后你就看到一下的效果 如果最后一个字段上面显示istio-injection=enabled则代表labels 设置成功 12NAME STATUS AGE LABELSdemo Active 24s istio-injection=enabled 部署 BookInfo 1$ kubectl apply -f istio/bookinfo.yml 查看 服务是否正常部署且 成功注入sidecar 1$ kubectl get po -n demo 确认 所有的service 和pod 都Running 12345678910111213141516171819$ kubectl get service -n demo NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdetails ClusterIP 10.0.0.31 &lt;none&gt; 9080/TCP 6mkubernetes ClusterIP 10.0.0.1 &lt;none&gt; 443/TCP 7dproductpage ClusterIP 10.0.0.120 &lt;none&gt; 9080/TCP 6mratings ClusterIP 10.0.0.15 &lt;none&gt; 9080/TCP 6mreviews ClusterIP 10.0.0.170 &lt;none&gt; 9080/TCP 6m$ kubectl get pods -n demoNAME READY STATUS RESTARTS AGEdetails-v1-1520924117-48z17 2/2 Running 0 6mproductpage-v1-560495357-jk1lz 2/2 Running 0 6mratings-v1-734492171-rnr5l 2/2 Running 0 6mreviews-v1-874083890-f0qf0 2/2 Running 0 6mreviews-v2-1343845940-b34q5 2/2 Running 0 6mreviews-v3-1813607990-8ch52 2/2 Running 0 6m 如果所有pod ready 显示 2/2 则 服务正确注入sidecar 流量管理配置服务访问如何将请求动态路由到微服务的多个版本。 istio Bookinfo示例包含四个单独的微服务，每个微服务具有多个版本。微服务之一的三种不同版本reviews已经部署并同时运行。为了说明此问题，请/productpage在浏览器中访问Bookinfo应用，然后刷新几次。您会注意到，有时书评输出中包含星级，有时则不。这是因为如果没有明确的默认服务版本可路由，Istio将以循环方式将请求路由到所有可用版本。 配置方式如下所示 12345678910111213141516171819202122232425262728293031323334353637383940414243444546apiVersion: networking.istio.io/v1beta1kind: Gatewaymetadata: name: bookinfo-gateway namespace: demospec: selector: istio: ingressgateway # istio-system 下面的istio-ingressgateway 的labels servers: - hosts: - &#x27;*&#x27; # 指定访问域名 port: name: http number: 80 # 访问端口 protocol: HTTP # 访问协议名称---apiVersion: networking.istio.io/v1beta1kind: VirtualServicemetadata: name: bookinfo namespace: demospec: gateways: - bookinfo-gateway # 网关gateway的名称 hosts: - &#x27;*&#x27; # 访问的svc 的名称 http: - match: - uri: exact: /productpage # 精确匹配 路径 - uri: prefix: /static # 前缀匹配路径 - uri: exact: /login - uri: exact: /logout - uri: prefix: /api/v1/products route: - destination: host: productpage # 目的服务 svc地址 port: number: 9080 # 目的端口 以上配置的名词解释 网关配置 gateway 必要字段的解释 字段名称 类型 描述 是否必须 selector map&lt;string, string&gt; 一个或多个标签，指示应在其上应用此网关配置的一组特定的Pod / VM。 默认情况下，基于标签选择器在所有名称空间中搜索工作负载。 这意味着名称空间“ foo”中的网关资源可以基于标签选择名称空间“ bar”中的pod。 可以通过istiod中的PILOTSCOPEGATEWAYTONAMESPACE环境变量来控制此行为。 如果将此变量设置为true，则标签搜索的范围将限于存在资源的配置名称空间。 换句话说，网关资源必须与网关工作负载实例位于相同的名称空间中。 如果选择器为零，则网关将应用于所有工作负载。 yes hosts []string 此网关公开的一台或多台主机。 尽管通常适用于HTTP服务，但也可以将其用于使用TLS和SNI的TCP服务。 主机被指定为带有可选名称空间/前缀的dnsName。 dnsName应该使用FQDN格式指定，可以选择在最左侧的组件中包含通配符（例如prod / .example.com）。 将dnsName设置为，以从指定的名称空间（例如prod / ）中选择所有VirtualService主机。可以将名称空间设置为或。，分别代表任意名称空间或当前名称空间。 例如，* / foo.example.com从任何可用的名称空间中选择服务，而./foo.example.com仅从Sidecar的名称空间中选择服务。 如果未指定名称空间/，则默认值为* /，即从任何名称空间中选择服务。 还将使用所选名称空间中的任何关联的DestinationRule。虚拟服务必须绑定到网关，并且必须具有一个或多个与服务器中指定的主机匹配的主机。 匹配可以是与服务器主机的完全匹配或后缀匹配。 例如，如果服务器的主机指定* .example.com，则具有主机dev.example.com或prod.example.com的VirtualService将匹配。 但是，带有主机example.com或newexample.com的VirtualService将不匹配。注意：仅可以引用导出到网关名称空间的虚拟服务（例如，exportTo值为*）。 私有配置（例如，exportTo设置为）将不可用。 有关详细信息，请参考VirtualService，DestinationRule和ServiceEntry配置中的exportTo设置。 yes port port 代理应在其上侦听传入连接的端口和协议 yes 获取效果如下 1234567➜ ~ kubectl get gw -n demoNAME AGEbookinfo-gateway 11m➜ ~ kubectl get vs -n demoNAME GATEWAYS HOSTS AGEbookinfo [bookinfo-gateway] [*] 11m VirtualService定义了一组寻址主机时要应用的流量路由规则。每个路由规则为特定协议的流量定义匹配条件。如果流量匹配，则将其发送到注册表中定义的命名目标服务（或其子集/版本）。 以下为VirtualService 字段的名词解释 字段名称 类型 描述 是否必须 hosts string[] hosts字段适用于HTTP和TCP服务。网格内的服务（即在服务注册表中找到的服务）必须始终使用其字母数字名称进行引用。IP地址仅允许通过网关定义的服务使用。 no gateways string[] 应应用这些路由的网关和sidecar的名称。其他名称空间中的网关可以由/;引用 。指定没有名称空间限定符的网关与指定VirtualService的名称空间相同 no subset string 服务中子集的名称。仅适用于网格内的服务。该子集必须在相应的DestinationRule中定义。 node port PortSelector 指定要寻址的主机上的端口。如果服务仅公开单个端口，则不需要显式选择端口。 no http HTTPRoute[] HTTP流量的路由规则的有序列表。HTTP路由将应用于名为“ http- ” /“ http2- ” /“ grpc- *”的平台服务端口，协议为HTTP / HTTP2 / GRPC / TLS终止的HTTPS的网关端口以及使用HTTP / HTTP2 /的服务入口端口GRPC协议。使用匹配传入请求的第一条规则。 no tls TLSRoute[] 未终止的TLS和HTTPS流量的路由规则的有序列表。路由通常使用ClientHello消息显示的SNI值执行。TLS路由将应用于使用HTTPS / TLS协议（即采用“直通” TLS模式）的名为“ https- ”，“ tls- ”的平台服务端口，未终止的网关端口以及使用HTTPS / TLS协议的服务入口端口。使用匹配传入请求的第一条规则。注意：没有关联虚拟服务的流量“ https- ”或“ tls- ”端口将被视为不透明的TCP流量。 no tcp TCPRoute[] 不透明TCP流量的路由规则的有序列表。TCP路由将应用于不是HTTP或TLS端口的任何端口。使用匹配传入请求的第一条规则。 no HTTP路由描述用于路由HTTP / 1.1，HTTP2和gRPC通信的匹配条件和操作。有关用法示例，请参见VirtualService。 字段名称 类型 描述 是否必须 name string 分配给路由以进行调试的名称。路由名称将与匹配名称串联在一起，并将被记录在访问日志中，以查找与此路由/匹配匹配的请求。 no match HTTPMatchRequest[] 匹配要激活的规则要满足的条件。单个匹配块内的所有条件都具有AND语义，而匹配块列表具有OR语义。如果任何一个匹配块成功，则匹配该规则。 no route HTTPRouteDestination[] HTTP规则可以重定向或转发（默认）流量。转发目标可以是服务的多个版本之一（请参阅文档开头的词汇表）。与服务版本关联的权重决定了它接收的流量比例。 no redirect HTTPRedirect HTTP规则可以重定向或转发（默认）流量。如果在规则中指定了流量通过选项，则将忽略路由/重定向。重定向原语可用于将HTTP 301重定向发送到其他URI或Authority。 no rewrite HTTPRewrite 重写HTTP URI和Authority标头。重写不能与重定向原语一起使用。重写将在转发之前执行。 no timeout Duration HTTP请求超时，默认为禁用。 no retries HTTPRetry 重试HTTP请求的策略。 no headers Headers 标头操作规则 no fault HTTPFaultInjection 故障注入策略，适用于客户端的HTTP通信。请注意，如果在客户端启用了错误，则不会启用超时或重试。 没有 mirror Destination 除了将请求转发到预期目标之外，还将HTTP流量镜像到另一个目标。镜像流量是基于尽力而为的，在这种情况下，边车/网关在从原始目的地返回响应之前不会等待镜像集群响应。将为镜像目标生成统计信息。 no http 和tcp 、tls 基本上类似 就不重复说明了 访问页面即可看到页面效果如下: 红色框的地方就是不同版本的 reviews 服务 请求超时要测试Bookinfo应用程序微服务的弹性，请为用户reviews:v2和的ratings微服务之间注入7s的延迟jason。此测试将发现故意引入Bookinfo应用程序的错误。 123456789101112131415161718192021222324252627$ kubectl get virtualservice ratings -o yamlapiVersion: networking.istio.io/v1beta1kind: VirtualServicemetadata: name: bookinfo-fault-injection namespace: demospec: hosts: - ratings http: - fault: delay: fixedDelay: 7s percentage: value: 100 match: - headers: end-user: exact: jason route: - destination: host: ratings subset: v1 - route: - destination: host: ratings subset: v1 产生的效果如下所示： 重新加载productpage网页。您将看到该页面实际上在大约6秒钟内加载完成。 意义:Istio启用协议特定的故障注入到网络中，而不是杀死pod，延迟或在TCP层破坏数据包。我们的理由是，无论网络级别的故障如何，应用层观察到的故障都是一样的，并且可以在应用层注入更有意义的故障（例如，HTTP错误代码），以锻炼应用的弹性。 运维人员可以为符合特定条件的请求配置故障。运维人员可以进一步限制应该遭受故障的请求的百分比。可以注入两种类型的故障：延迟和中止。延迟是计时故障，模拟增加的网络延迟或过载的上游服务。中止是模拟上游服务的崩溃故障。中止通常以HTTP错误代码或TCP连接失败的形式表现。 流量分配一个常见的用例是将流量逐渐从一种微服务版本迁移到另一种。在Istio中，您可以通过配置一系列规则以将一定百分比的流量路由到一项服务或另一项服务来实现此目标。在此任务中，您将发送流量的10％reviews:v1和90％ reviews:v3。然后，您将100％的流量发送到来完成迁移reviews:v3。 现在来创建我的配置吧 12345678910111213141516171819202122232425262728293031323334353637apiVersion: networking.istio.io/v1beta1kind: VirtualServicemetadata: name: bookinfo-traffic-injection namespace: demospec: hosts: - reviews http: - route: - destination: host: reviews subset: v1 # 需要和DestinationRule 资源的名字对应起来 weight: 10 - destination: host: reviews subset: v3 weight: 90---apiVersion: networking.istio.io/v1alpha3kind: DestinationRulemetadata: name: bookinfo-traffic-injection namespace: demospec: host: reviews subsets: - name: v1 # subset指向的名称 labels: version: v1 # 需要路由到pod labels中的version版本对应的值 - name: v2 labels: version: v2 - name: v3 labels: version: v3 创建以上配置 1$ kubectl apply -f bookinfo-traffic-injection.yaml 将istio-system下面的kiali的svc地址改成nodeport 访问即可， 默认登陆的用户名密码是 admin/admin 以上是我们还没有配置分配流量时的流量视图，我们可以看到reviews这个服务的三个不同版本的pod都是平均分配的 大约所占比例是33%左右。 现在我们配置了流量分配再看看是什么样子的。 我们会发现红色星的次数明显要多余没有星的次数多很多 我们现在可以借助kiali来看看我们请求的流量视图 可以看到reviews不同版本的服务所占比例分别是 v1 ---&gt;14.3% ，v2 ---&gt; 0% , v3 ---&gt; 85.7% 现在我们istio的流量分配的设置已经成功了，那么istio的流量分配的意义在哪里，有什么作用呢? 意义:您可以通过 istio 指定特定服务按照你的设定指定转到金丝雀版本，而不必考虑金丝雀部署的大小，或根据请求的内容将流量发送到特定版本。 给服务注入故障熔断流量镜像问题定位在istio中有一个很麻烦的问题 就是配置出错以后很难定位是什么配置错误导致访问出错的问题，所以我们需要专门的工具来定位是什么导致的配置问题。 安全证书管理认证方式参考文档","categories":[],"tags":[{"name":"istio","slug":"istio","permalink":"http://example.com/tags/istio/"}]},{"title":"普通队列","slug":"queue","date":"2020-09-20T16:00:00.000Z","updated":"2021-03-09T14:27:18.490Z","comments":true,"path":"2020/09/21/queue/","link":"","permalink":"http://example.com/2020/09/21/queue/","excerpt":"","text":"普通队列 普通的队列是一种先进先出的数据结构，元素在队列尾追加，而从队列头删除。 什么是堆堆是一颗具有特定性质的二叉树，堆的基本要求就是堆中所有结点的值必须大于或等于（或小于或等于）其孩子结点的值，这也称为堆的性质；堆还有另一个性质，就是当 h &gt; 0 时，所有叶子结点都处于第 h 或 h - 1 层（其中 h 为树的高度，完全二叉树），也就是说，堆应该是一颗完全二叉树； 什么是二叉树优先队列优先队列不再遵循先入先出的原则，而是分为两种情况： 最大优先队列，无论入队顺序，当前最大的元素优先出队。 最小优先队列，无论入队顺序，当前最小的元素优先出队。 比如有一个最大优先队列，它的最大元素是8，那么虽然元素8并不是队首元素，但出队的时候仍然让元素8首先出队：","categories":[],"tags":[]},{"title":"更改docker默认挂载目录","slug":"docker","date":"2020-09-20T16:00:00.000Z","updated":"2021-03-09T14:28:30.673Z","comments":true,"path":"2020/09/21/docker/","link":"","permalink":"http://example.com/2020/09/21/docker/","excerpt":"","text":"更改docker默认挂载目录 场景生产上运行了一段时间docker后，根分区使用量报警，由于根分区不是lvm类型的，所以无法做扩容，故采用新加一块硬盘，挂载到新目录/docker/，并将docker默认挂载目录改到这个目录的方法解决磁盘将满的问题。 新加磁盘并挂载1234567fdisk /dev/vdb过程略mkfs.xfs /dev/vdb1mkdir /dockermount /dev/vdc1 /docker 1234[root@cloud-jumpserver01 ~]# blkid /dev/vdc1: UUID=&quot;27d703ee-41b1-4b7e-860b-aa465b807e39&quot; TYPE=&quot;xfs&quot; cat /etc/fstab UUID=27d703ee-41b1-4b7e-860b-aa465b807e39 /dev/vdc1 xfs defaults 1 1 更改docker挂载目录1234cat /etc/docker/daemon.json &#123;&quot;registry-mirrors&quot;: [&quot;http://f1361db2.m.daocloud.io&quot;],&quot;data-root&quot;: &quot;/docker&quot;&#125; 加载配置12systemctl daemon-reloadsystemctl restart docker 验证挂载目录是否更改123docker infoDocker Root Dir: /docker 1docker ps -a 说明：这时候如果docker ps -a是不会有任何输出的。 复制文件到新的挂载目录1cp -arp /var/lib/docker/* /docker/ 说明：提示是否覆盖文件，选择是。 重启docker1systemctl restart docker 验证旧容器是否正常1234docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES11ea907c531e jumpserver/jms_guacamole:1.5.3 &quot;/init&quot; 12 months ago Up 4 minutes 127.0.0.1:8081-&gt;8080/tcp jms_guacamolec9b5a730f6ec jumpserver/jms_koko:1.5.3 &quot;./entrypoint.sh&quot; 12 months ago Up 4 minutes 0.0.0.0:2222-&gt;2222/tcp, 127.0.0.1:5000-&gt;5000/tcp jms_koko","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"}]},{"title":"Compare","slug":"compare","date":"2020-03-09T10:36:28.000Z","updated":"2021-03-09T14:27:59.696Z","comments":true,"path":"2020/03/09/compare/","link":"","permalink":"http://example.com/2020/03/09/compare/","excerpt":"","text":"Compare比较大小的基本方法 1234567891011121314151617181920212223242526272829303132333435package compareimport ( &quot;fmt&quot; &quot;github.com/clarechu/algorithms/code/models&quot;)func show(comparable []*models.Comparable) &#123; for i := 0; i &lt; len(comparable); i++ &#123; fmt.Println(comparable[i].Value) &#125;&#125;//isSorted 查看当前数组是否按照顺序排序func isSorted(comparable []*models.Comparable) bool &#123; for i := 1; i &lt; len(comparable); i++ &#123; if less(comparable[i], comparable[i-1]) &#123; return false &#125; &#125; return true&#125;//less v &gt; wfunc less(v, w *models.Comparable) bool &#123; return v.Value &lt; w.Value&#125;//exchangefunc exchange(comparable []*models.Comparable, i, j int) &#123; c := comparable[i] comparable[i] = comparable[j] comparable[j] = c&#125; 选择排序 1234567891011121314func selectSort(a []*models.Comparable) &#123; n := len(a) for i := 0; i &lt; n; i++ &#123; min := i for j := i + 1; j &lt; n; j++ &#123; if less(a[j], a[min]) &#123; min = j &#125; &#125; exchange(a, min, i) &#125;&#125; 插入排序 12345678910func insertionSort(a []*models.Comparable) &#123; n := len(a) for i := 0; i &lt; n; i++ &#123; for j := i; j &gt; 0 &amp;&amp; less(a[j], a[j-1]); j-- &#123; exchange(a, j, j-1) &#125; &#125;&#125; 归并排序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//Merge Sort 归并排序func mergeSort(a []*models.Comparable) &#123; l := len(a) mSort(a, 0, l-1)&#125;func mSort(a []*models.Comparable, lo, hi int) &#123; if hi &lt;= lo &#123; return &#125; mid := lo + (hi-lo)/2 mSort(a, lo, mid) mSort(a, mid+1, hi) merge(a, lo, mid, hi)&#125;//merge 合并数组// lo 初始位置// min 中位// hi 高位func merge(a []*models.Comparable, lo, mid, hi int) &#123; i, j := lo, mid+1 d := make([]*models.Comparable, 0) for _, k := range a &#123; d = append(d, k) &#125; for k := lo; k &lt;= hi; k++ &#123; // 左边取完了 取右边的 if i &gt; mid &#123; a[k] = d[j] j++ // 右边取完了 取左边的 &#125; else if j &gt; hi &#123; a[k] = d[i] i++ &#125; else if less(d[j], d[i]) &#123; a[k] = d[j] j++ &#125; else &#123; a[k] = d[i] i++ &#125; &#125;&#125; 快速排序 123456789101112131415161718192021222324252627282930313233func quick(a []*models.Comparable, lo, hi int) &#123; if lo &gt;= hi &#123; return &#125; k := a[lo] i, j := lo, hi for &#123; for ; i &lt; j; j-- &#123; if less(a[j], k) &#123; break &#125; &#125; if i &lt; j &#123; a[i] = a[j] i++ &#125; for ; i &lt; j; i++ &#123; if less(k, a[i]) &#123; break &#125; &#125; if i &lt; j &#123; a[j] = a[i] j-- &#125; if i &gt;= j &#123; break &#125; &#125; a[i] = k quick(a, lo, i-1) quick(a, i+1, hi)&#125;","categories":[],"tags":[]},{"title":"阿里K8S节点初始化","slug":"doc-dev/ops/k8s-node","date":"2019-03-11T16:00:00.000Z","updated":"2021-03-09T14:26:08.687Z","comments":true,"path":"2019/03/12/doc-dev/ops/k8s-node/","link":"","permalink":"http://example.com/2019/03/12/doc-dev/ops/k8s-node/","excerpt":"","text":"修改默认DNS12345cd /etc/sysconfig/network-scripts# 增加默认搜索域为siss.aliyun,并配置DNS为内部的DNSecho -e &quot;DOMAIN=siss.aliyun\\nDNS1=172.18.171.109\\nDNS2=172.18.171.113&quot; &gt;&gt; ifcfg-eth0# 重启网络systemctl restart network 安装监控组件Zabbix Agent12rpm -ivh https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpmyum install zabbix-agent -y 替换默认配置12345678910# 替换默认的日志文件轮替sed -i &#x27;s/LogFileSize=0/LogFileSize=1/g&#x27; /etc/zabbix/zabbix_agentd.conf# 替换默认的127.0.0.1sed -i &#x27;s/127.0.0.1/zabbix.siss.aliyun/g&#x27; /etc/zabbix/zabbix_agentd.conf# 替换Hostnamesed -i &quot;s/Hostname=Zabbix server/Hostname=$(hostname)/g&quot; /etc/zabbix/zabbix_agentd.conf# 替换HostMetased -i &#x27;s/# HostMetadata=/HostMetadata=linux/g&#x27; /etc/zabbix/zabbix_agentd.conf# 启动服务systemctl restart zabbix-agent&amp;&amp;systemctl enable zabbix-agent 系统日志远端收集修改系统的rsyslog，将本地日志发送至远端 1234567# vim /etc/rsyslog.conf...# 添加至文件最后*.* @graylog.siss.aliyun:514;RSYSLOG_SyslogProtocol23Format# 重启服务systemctl restart rsyslog","categories":[],"tags":[]},{"title":"操作系统标准化","slug":"doc-dev/ops/standard","date":"2019-03-11T16:00:00.000Z","updated":"2021-03-09T14:26:12.864Z","comments":true,"path":"2019/03/12/doc-dev/ops/standard/","link":"","permalink":"http://example.com/2019/03/12/doc-dev/ops/standard/","excerpt":"","text":"使用内部DNS服务器123echo &quot;nameserver 172.18.171.113&quot; &gt; /etc/resolv.confecho &quot;nameserver 172.18.171.109&quot; &gt;&gt; /etc/resolv.conf# 另外需要将网卡配置加上本地DNS配置，防止重启丢失DNS 内核参数调整12345678910111213141516171819202122232425vim /etc/sysctl.d/110-siss.conf# IPv4转发开启net.ipv4.ip_forward = 1# 开启TCP连接中TIME-WAIT sockets的快速回收net.ipv4.tcp_tw_recycle = 1# 开启TCP连接复用net.ipv4.tcp_tw_reuse = 1# 开启对于TCP时间戳的支持net.ipv4.tcp_timestamps = 1# 出现SYN等待队列溢出时启用cookie处理，防范少量的SYN攻击。net.ipv4.tcp_syncookies = 1# 本地发起连接的端口范围net.ipv4.ip_local_port_range = 1024 65000# 监听端口的最大队列长度net.core.somaxconn = 16384# 应用参数sysctl -p /etc/sysct.d/110-siss.conf 数据卷使用LVM，并独立挂载12345678910# 查看系统所有磁盘fdisk -l#假设空白磁盘为/dev/xvdc,建立PV/VG/LVpvcreate /dev/xvdc &amp;&amp; vgcreate data /dev/xvdclvcreate -n data -l 100%VG data &amp;&amp; mkfs.xfs /dev/data/datamkidr /dataecho &quot;/dev/data/data /data xfs defaults 1 1&quot; &gt;&gt; /etc/fstabmount -a 基础包安装123curl https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo &gt; docker-ce.reporpm -ivh https://mirrors.aliyun.com/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpmyum install docker-ce vmstatus zabbix-agent -y Docker默认参数修改123456789vim /etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opt&quot;: &#123; &quot;max-file&quot;: &quot;10&quot;, &quot;max-size&quot;: &quot;10M&quot; &#125;, &quot;data-root&quot;: &quot;/data/docker&quot;&#125; 文件资源限制修改12345vim /etc/security/limits.conf* soft nofile 65536* hard nofile 65536* soft nproc 65536* soft nproc 65536 系统日志收集与调整 限制默认journald产生的日志大小，防止撑爆磁盘 12345vim /etc/systemd/journald.confSystemMaxUse=50MRuntimeMaxUse=50MSystemMaxFiles=10RuntimeMaxFiles=10 默认rsyslog日志发送到统一日志收集器(graylog2) 1234vim /etc/rsyslog.conf# graylog.siss.io为GrayLog服务器地址*.* @graylog.siss.io:514;RSYSLOG_SyslogProtocol23Formatsystemctl restart rsyslog Ansible公钥预存放脚本下载centos7_init.sh","categories":[],"tags":[]},{"title":"本地开发环境基础服务支持使用DNS设置方法","slug":"doc-dev/ops/use_dns","date":"2019-03-11T16:00:00.000Z","updated":"2021-03-09T14:26:16.893Z","comments":true,"path":"2019/03/12/doc-dev/ops/use_dns/","link":"","permalink":"http://example.com/2019/03/12/doc-dev/ops/use_dns/","excerpt":"","text":"修改Windows设置进入控制面板—-&gt;网络连接—&gt;本地连接 在弹出的菜单中，点击属性按钮 弹出的菜单中，先选中Internet协议版本4—再点击属性 将首选DNS修改为128.0.100.170 再点击高级按钮,弹出的对话框切换到DNS选项卡，如下图所示 选中附加这些DNS后续，再点击添加。添加完成后再点击确定，最后依次关闭当前窗口 测试打开终端命令行窗口，执行ping mysql-dev,应该会自动将mysql-dev转换为mysql-dev.siss.io该域名，并正确返回IP地址 附:开发环境信息","categories":[],"tags":[]},{"title":"本地YUM源搭建","slug":"doc-dev/ops/yum","date":"2019-03-11T16:00:00.000Z","updated":"2021-03-09T14:26:22.554Z","comments":true,"path":"2019/03/12/doc-dev/ops/yum/","link":"","permalink":"http://example.com/2019/03/12/doc-dev/ops/yum/","excerpt":"","text":"Linux系统的包管理是yum。默认刚安装好的系统一般都是从CentOS官方下载相关软件包，这样就会浪费很多带宽。 服务端配置12345# 安装yum-utilsyum install yum-utils createrepo nginx -y# 准备存储YUM源数据的文件夹mkdir -p /data/yumdata 同步脚本下载 syncRepo.sh 1yum repolist 12345678910111213141516171819# 执行脚本，同步yum源以及生成yum源数据cd /data/yumdatachmod +x syncRepo.shsh syncRepos.h# 修改NGINX配置文件,将同步至本地的YUM通过HTTP给内部使用vi /etc/nginx/nginx.conf...location / &#123; autoindex on; root /data/yumdata/;&#125;# 开启NGINXsystemctl enable nginx &amp;&amp; systemctl start nginx# 加入定时任务，每天自动同上层yuvim /etc/crontab2 3 * * * root /data/yumdata/syncRepo.sh 客户端配置 先备份系统原有的repo文件 12cd /etc/yum.repos.d &amp;&amp; mkdir backupmv *.repo backup 在/etc/yum.repos.d/目录下新建本地YUM源的文件 12345678910111213141516171819202122232425262728293031vim /etc/yum.repos.d/local.repo[centos-base]name=CentOS-Basebaseurl=http://128.0.100.170/base/enable=1gpgcheck=0[centos-update]name=CentOS-Updatebaseurl=http://128.0.100.170/updates/enable=1gpgcheck=0[centos-extrals]name=CentOS-Extralsbaseurl=http://128.0.100.170/extras/enable=1gpgcheck=0[centos-epel]name=CentOS-EPELbaseurl=http://128.0.100.170/epel/enable=1gpgcheck=0[docker-ce]name=Docker-CEbaseurl=http://128.0.100.170/docker-ce/enable=1gpgcheck=0","categories":[],"tags":[]},{"title":"SpringBoot整合Swagger2","slug":"doc-dev/standard/Swagger2","date":"2019-03-11T16:00:00.000Z","updated":"2021-03-09T14:26:29.388Z","comments":true,"path":"2019/03/12/doc-dev/standard/Swagger2/","link":"","permalink":"http://example.com/2019/03/12/doc-dev/standard/Swagger2/","excerpt":"","text":"前言手写Api文档的几个痛点： 文档需要更新的时候，需要再次发送一份给前端，也就是文档更新交流不及时。 接口返回结果不明确 不能直接在线测试接口，通常需要使用工具，比如postman 接口文档太多，不好管理 Swagger也就是为了解决这个问题，当然也不能说Swagger就一定是完美的，当然也有缺点，最明显的就是代码移入性比较强。 使用在pom.xml中添加依赖 123456789101112&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt;&lt;/dependency&gt; 在启动类中添加swagger 开关 12345678@SpringBootApplication@EnableSwagger2public class SpringbootSwagger2Application &#123;public static void main(String[] args) &#123; SpringApplication.run(SpringbootSwagger2Application.class, args);&#125;&#125; 测试的demo123456789101112131415161718192021222324252627282930@RestController@Api(&quot;Hello-world 相关api&quot;)public class HelloWorld &#123; @Autowired private HelloRpcService helloRpcService; @Autowired private RedisTemplate redisTemplate; @Autowired private KafkaTemplate kafkaTemplate; @ApiOperation(&quot;调用rpc服务&quot;) @ApiImplicitParams(&#123; @ApiImplicitParam(paramType=&quot;header&quot;,name=&quot;username&quot;,dataType=&quot;String&quot;,required=true,value=&quot;用户的姓名&quot;,defaultValue=&quot;xxxx&quot;), @ApiImplicitParam(paramType=&quot;query&quot;,name=&quot;password&quot;,dataType=&quot;String&quot;,required=true,value=&quot;用户的密码&quot;,defaultValue=&quot;xxxxxxxxxxxx&quot;) &#125;) @ApiResponses(&#123; @ApiResponse(code=400,message=&quot;请求参数没填好&quot;), @ApiResponse(code=404,message=&quot;请求路径没有或页面跳转路径不对&quot;), @ApiResponse(code=500,message=&quot;服务器异常&quot;) &#125;) @RequestMapping(value = &quot;/qq&quot;, method = RequestMethod.POST) public Object get(@RequestBody User user)&#123; System.out.println(&quot;controller get method&quot;); Hello b = helloRpcService.get(&quot;qq&quot;); return b; &#125;&#125; 得到一下效果 Swagger注解swagger通过注解表明该接口会生成文档，包括接口名、请求方法、参数、返回信息的等等。 @Api：修饰整个类，描述Controller的作用@ApiOperation：描述一个类的一个方法，或者说一个接口@ApiParam：单个参数描述@ApiModel：用对象来接收参数@ApiProperty：用对象接收参数时，描述对象的一个字段@ApiResponse：HTTP响应其中1个描述@ApiResponses：HTTP响应整体描述@ApiIgnore：使用该注解忽略这个API@ApiError ：发生错误返回的信息@ApiImplicitParam：一个请求参数@ApiImplicitParams：多个请求参数","categories":[],"tags":[]},{"title":"Sharding-JDBC 的使用","slug":"doc-dev/basics/sharding-jdbc","date":"2018-03-11T16:00:00.000Z","updated":"2021-03-09T14:25:27.994Z","comments":true,"path":"2018/03/12/doc-dev/basics/sharding-jdbc/","link":"","permalink":"http://example.com/2018/03/12/doc-dev/basics/sharding-jdbc/","excerpt":"","text":"简介 Sharding-JDBC是当当应用框架ddframe中，从关系型数据库模块dd-rdb中分离出来的数据库水平分片框架，实现透明化数据库分库分表访问。Sharding-JDBC是继dubbox和elastic-job之后，ddframe系列开源的第3个项目。Sharding-JDBC直接封装JDBC协议，可以理解为增强版的JDBC驱动，旧代码迁移成本几乎为零。Sharding-JDBC定位为轻量级java框架，使用客户端直连数据库，以jar包形式提供服务，无proxy代理层，无需额外部署，无其他依赖，DBA也无需改变原有的运维方式。 主要包括以下特点： 可适用于任何基于java的ORM框架，如：JPA, Hibernate, Mybatis, Spring JDBC Template或直接使用JDBC。可基于任何第三方的数据库连接池，如：DBCP, C3P0, BoneCP, Druid等。 理论上可支持任意实现JDBC规范的数据库。虽然目前仅支持MySQL，但已有支持Oracle，SQLServer等数据库的计划。分片策略灵活，可支持等号，between，in等多维度分片，也可支持多分片键。 SQL解析功能完善，支持聚合，分组，排序，limit，or等查询，并支持Binding Table以及笛卡尔积表查询。性能高。单库查询QPS为原生JDBC的99.8%；双库查询QPS比单库增加94%。 Sharding-JDBC结合SpringBoot注意 1、代码中类似”ds0..1.torder0..1.torder{0..1}”成为行表达式，形如”expression或expression或-&gt;{ expression }”。该表达式可用于配置数据节点和配置分片算法。 ${begin..end}表示范围区间，即表示从begin到end个 ${[unit1, unit2, unit_x]}表示枚举值 2、orderTableRuleConfig.setActualDataNodes(“ds0..1.torder0..1.torder{0..1}”); 这里表示的是使用行表达式配置数据节点即数据库分别是ds0、ds1,表分别是t_order0、t_order1。 该表达的等价组合是：ds0.t_order0, ds0.t_order1, ds1.t_order0, ds1.t_order1。 3、orderTableRuleConfig.setTableShardingStrategyConfig(new InlineShardingStrategyConfiguration(“order_id”, “t_order${order_id % 2}”)); 这里表示的是使用行表达式配置分片算法。该行表示针对t_order表中的元素按照order_id模2将不同的元素放进不同的表中。 比如order_id=5，5%2=1，则放入t_order1中 order_id=6, 6%2=0, 则放入t_order0中 4、除此以外还要一些类似”逻辑表”这样的概念，可以到官方文档自行查询。 工具类DataRespository(该类来源sharding-sphere-example项目)","categories":[],"tags":[]},{"title":"针对 数据的校验","slug":"doc-dev/basics/validate","date":"2018-03-11T16:00:00.000Z","updated":"2021-03-09T14:25:12.163Z","comments":true,"path":"2018/03/12/doc-dev/basics/validate/","link":"","permalink":"http://example.com/2018/03/12/doc-dev/basics/validate/","excerpt":"","text":"Hibernate Validator 简介 平时项目中，难免需要对参数 进行一些参数正确性的校验，这些校验出现在业务代码中，让我们的业务代码显得臃肿，而且，频繁的编写这类参数校验代码很无聊。鉴于此，觉得 Hibernate Validator 框架刚好解决了这些问题，可以很优雅的方式实现参数的校验，让业务代码 和 校验逻辑 分开,不再编写重复的校验逻辑。 Hibernate Validator 是 Bean Validation 的参考实现 . Hibernate Validator 提供了 JSR 303 规范中所有内置 constraint 的实现，除此之外还有一些附加的 constraint。Bean Validation 为 JavaBean 验证定义了相应的元数据模型和API。缺省的元数据是 Java Annotations，通过使用 XML 可以对原有的元数据信息进行覆盖和扩展。Bean Validation 是一个运行时的数据验证框架，在验证之后验证的错误信息会被马上返回。 Hibernate Validator 的作用 验证逻辑与业务逻辑之间进行了分离，降低了程序耦合度； 统一且规范的验证方式，无需你再次编写重复的验证代码； 你将更专注于你的业务，将这些繁琐的事情统统丢在一边。 spring boot 结合hibernate来进行数据校验项目中，主要用于接口api 的入参校验和 封装工具类 在代码中校验两种使用方式。 引入jar包 1234&lt;dependency&gt; &lt;groupId&gt;cn.com.siss&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-validate&lt;/artifactId&gt;&lt;/dependency&gt; 使用 方法 ValidationUtils.validate(itemInfo); 1234567891011@RestControllerpublic class DemoController &#123; @RequestMapping(value = &quot;demo&quot;, method = RequestMethod.GET) public void demo(@RequestBody ItemInfo itemInfo) throws DataException &#123; ValidationUtils.validate(itemInfo); &#125;&#125; 常用注解有以下几种形式： |注解|支持的数据类型|作用|Hibernate元数据影响||:—:|:—:|:—:|:—:|:—:||@AssertFalse|Boolean, boolean|检查带注释的元素是否为 false|没有||@AssertTrue|Boolean, boolean|检查带注释的元素是否为 true|没有||@DecimalMax|BigDecimal， BigInteger， String， byte， short， int， long 和原始类型的相应的包装。另外由HV支持：任何子类型 Number。|被标注的值必须不大于约束中指定的最大值. 这个约束的参数是一个通过BigDecimal定义的最大值的字符串表示.|没有||@DecimalMin|BigDecimal， BigInteger， String， byte， short， int， long 和原始类型的相应的包装。另外由HV支持：任何子类型 Number。|被标注的值必须不小于约束中指定的最小值. 这个约束的参数是一个通过BigDecimal定义的最小值的字符串表示.|没有||@Digits（integer =，fraction =）|BigDecimal， BigInteger， String， byte， short， int， long 和原始类型的相应的包装。另外由HV支持：任何子类型 Number。|检查带注释的值是否是具有最多 integer 数字和 fraction 小数位的数字。 |对应的数据库表字段会被设置精度(precision)和准度(scale).||@Future|java.util.Date， java.util.Calendar; 另外由HV支持，如果 Joda Time 日期/时间API在类路径上：任何ReadablePartial 和和的 实现 ReadableInstant。|检查给定的日期是否比现在晚.|没有||@Max|BigDecimal， BigInteger， byte， short， int， long 和原始类型的相应的包装。另外由HV支持:( String 评估由String表示的数值），任何子类型 Number|检查该值是否小于或等于约束条件中指定的最大值.|会给对应的数据库表字段添加一个check的约束条件.||@Min|BigDecimal， BigInteger， byte， short， int， long 和原始类型的相应的包装。另外由HV支持:( String 评估由String表示的数值），任何子类型 Number|检查该值是否大于或等于约束条件中规定的最小值.|会给对应的数据库表字段添加一个check的约束条件.||@NotNull|没有限制|检测该值 不能为空|对应的表字段不允许为null.||@Null|没有限制|为空|||@Past|java.util.Date， java.util.Calendar; 另外由HV支持，如果 Joda Time 日期/时间API在类路径上：任何ReadablePartial 和和的 实现 ReadableInstant。|检查标注对象中的值表示的日期比当前早.|没有||@Pattern(regex=, flag=)|String|检查该字符串是否能够在match指定的情况下被regex定义的正则表达式匹配.|没有||@Size(min=, max=)|检查该值在min max之间|对应的数据库表字段的长度会被设置成约束中定义的最大值.|没有||@Valid|任何非基本类型|递归的对关联对象进行校验, 如果关联对象是个集合或者数组, 那么对其中的元素进行递归校验,如果是一个map,则对其中的值部分进行校验.|没有|","categories":[],"tags":[]},{"title":"SpringBoot 事务的管理","slug":"doc-dev/basics/transactional","date":"2018-03-11T16:00:00.000Z","updated":"2021-03-09T14:25:28.759Z","comments":true,"path":"2018/03/12/doc-dev/basics/transactional/","link":"","permalink":"http://example.com/2018/03/12/doc-dev/basics/transactional/","excerpt":"","text":"我们在开发企业应用时，对于业务人员的一个操作实际是对数据读写的多步操作的结合。由于数据操作在顺序执行的过程中，任何一步操作都有可能发生异常，异常会导致后续操作无法完成，此时由于业务逻辑并未正确的完成，之前成功操作数据的并不可靠，需要在这种情况下进行回退。 事务的作用就是为了保证用户的每一个操作都是可靠的，事务中的每一步操作都必须成功执行，只要有发生异常就回退到事务开始未进行操作的状态。 事务管理是Spring框架中最为常用的功能之一，我们在使用Spring Boot开发应用时，大部分情况下也都需要使用事务。 在业务层使用 @Transactional 开启事务，执行数据库操作后抛出异常。具体代码如下： 1234567@Transactionalpublic void addMoney() throws Exception &#123; //先增加余额 accountMapper.addMoney(); //然后遇到故障 throw new RuntimeException(&quot;发生异常了..&quot;);&#125; 数据库层就很简单了，我们通过注解来实现账户数据的查询，具体如下： 1234567891011package com.hehe.mapper;@Mapperpublic interface AccountMapper &#123; @Select(&quot;select * from account where account_id=1&quot;) Account getAccount(); @Update(&quot;update account set balance = balance+100 where account_id=1&quot;) void addMoney();&#125;","categories":[],"tags":[]},{"title":"Redis的使用","slug":"doc-dev/basics/redis","date":"2018-02-25T16:00:00.000Z","updated":"2021-03-09T14:24:44.266Z","comments":true,"path":"2018/02/26/doc-dev/basics/redis/","link":"","permalink":"http://example.com/2018/02/26/doc-dev/basics/redis/","excerpt":"","text":"简介Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。 Redis 与其他 key - value 缓存产品有以下三个特点： Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 Redis 优势 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 Redis的使用本章介绍如何使用SpringBoot 对redis的操作。 添加redis的 starter 修改pom.xml 12345&lt;dependency&gt; &lt;groupId&gt;cn.com.siss&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt; &lt;version&gt;$&#123;starters.version&#125;&lt;/version&gt;&lt;/dependency&gt; 添加application.yml的配置文件 单节点redis 12345678spring: profiles: include: - redisapp: redis: host: redis-dev-3 # redis 服务端ip地址 password: redis.123 # redis 登录密码 哨兵模式 123456789app: redis: password: redis.123 nodes: redis-dev-1:26379,redis-dev-2:26379,redis-dev-3:26379spring: profiles: include: - redis-sentry 添加string类型 首先通过注解@Autowired 注入redisTemplate.RedisTemplateUtil.set(redisTemplate, “p”, “{&quot;a&quot;: &quot;b&quot;}”, 3600L);第二个参数为key 第三个为value 最后一位为失效时间expireTime 1234567891011121314@RestControllerpublic class HelloWorld &#123; @Autowired private RedisTemplate redisTemplate; @RequestMapping(value = &quot;/set/redis&quot;, method = RequestMethod.GET) public Boolean setRedis()&#123; System.out.println(&quot;controller set method&quot;); boolean a = RedisTemplateUtil.set(redisTemplate, &quot;p&quot;, &quot;&#123;\\&quot;a\\&quot;: \\&quot;b\\&quot;&#125;&quot;, 3600L); return a; &#125;&#125; 修改数据库 redis默认有16个数据库 通过jedis来切换数据库，例如： 12JedisConnectionFactory jedisConnectionFactory = (JedisConnectionFactory) redisTemplate.getConnectionFactory();jedisConnectionFactory.setDatabase(2); 插入hash 12345678@Testpublic void checkoutSetHmKey() &#123; HashOperations&lt;String, Object, Object&gt; hash = redisTemplate.opsForHash(); Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put(&quot;a&quot;, &quot;b&quot;); hash.putAll(&quot;124242114234214123412&quot;, map); RedisTemplateUtil.hmSet(redisTemplate, &quot;s&quot;, &quot;a&quot;, &quot;b&quot;);&#125; 使用Redis注解方式插入缓存开启注释方式的redis 123456789@SpringBootApplication@EnableCachingpublic class SpringBootStarterRedisApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootStarterRedisApplication.class, args); &#125;&#125; 1234567cacheNames &#x3D; &quot;product&quot; &#x2F;&#x2F;缓存名key &#x3D; &quot;固定值&quot; 或 key &#x3D; &quot;#sellerid&quot;(可变化的值) &#x2F;&#x2F;redis缓存中的keycondition &#x3D; &quot;#sellerid.length &gt; 10&quot; &#x2F;&#x2F;里面填写表达式，true表示进行缓存，false表示不进行缓存unless &#x3D; &quot;#result.getCode() !&#x3D; 0&quot; &#x2F;&#x2F;和以上相反，当为false时进行缓存，否则不进行缓存 使用注解的方式更新缓存 12345678910@Cacheable(value=&quot;user&quot;, key=&quot;&#x27;users_&#x27;+#id&quot;)public User redis(Long id)&#123; User user = new User(); user.setUsername(&quot;hlhdidi&quot;); user.setPassword(&quot;123&quot;); user.setUid(1); user.setId(1L); System.out.println(&quot;log4j2坏啦?&quot;); return user;&#125; @CacheEvict 删除缓存 allEntries = false 清空product里面的所有制 allEntries = true 默认值，删除key对应的值 12345@CacheEvict(value=&quot;thisredis&quot;, key=&quot;&#x27;users_&#x27;+#id&quot;,condition=&quot;#id!=1&quot;)public void delUser(Integer id) &#123; // 删除user System.out.println(&quot;user删除&quot;);&#125; @CachePut 每次执行都会执行方法，无论缓存里是否有值，同时使用新的返回值的替换缓存中的值。这里不同于@Cacheable：@Cacheable如果缓存没有值，从则执行方法并缓存数据，如果缓存有值，则从缓存中获取值 @CacheConfig @CacheConfig: 类级别的注解：如果我们在此注解中定义cacheNames，则此类中的所有方法上 @Cacheable的cacheNames默认都是此值。当然@Cacheable也可以重定义cacheNames的值","categories":[],"tags":[]},{"title":"MongoDB的使用","slug":"doc-dev/basics/mongo","date":"2018-02-25T16:00:00.000Z","updated":"2021-03-09T14:24:32.103Z","comments":true,"path":"2018/02/26/doc-dev/basics/mongo/","link":"","permalink":"http://example.com/2018/02/26/doc-dev/basics/mongo/","excerpt":"","text":"简介MongoDB（来自于英文单词“Humongous”，中文含义为“庞大”）是可以应用于各种规模的企业、各个行业以及各类应用程序的开源数据库。作为一个适用于敏捷开发的数据库，MongoDB的数据模式可以随着应用程序的发展而灵活地更新。与此同时，它也为开发人员 提供了传统数据库的功能：二级索引，完整的查询系统以及严格一致性等等。 MongoDB能够使企业更加具有敏捷性和可扩展性，各种规模的企业都可以通过使用MongoDB来创建新的应用，提高与客户之间的工作效率，加快产品上市时间，以及降低企业成本。 MongoDB是专为可扩展性，高性能和高可用性而设计的数据库。它可以从单服务器部署扩展到大型、复杂的多数据中心架构。利用内存计算的优势，MongoDB能够提供高性能的数据读写操作。 MongoDB的本地复制和自动故障转移功能使您的应用程序具有企业级的可靠性和操作灵活性。 1、High performance - 对数据库高并发读写的需求web2.0 网站要根据用户个性化信息来实时生成动态页面和提供动态信息，所以基本上无法使用动态页面静态化技术，因此数据库并发负载非常高，往往要达到每秒上万次读写请求。 关系型数据库应付上万次 SQL 查询还勉强顶得住，但是应付上万次 SQL 写数据请求，硬盘IO 就已经无法承受了，其实对于普通的 BBS 网站，往往也存在对高并发写请求的需求。 2、Huge Storage - 对海量数据的高效率存储和访问的需求 对于大型的 SNS 网站，每天用户产生海量的用户动态信息，以国外的 Friend feed 为例，一个月就达到了 2.5 亿条用户动态，对于关系数据库来说，在一张 2.5 亿条记录的表里面进行SQL 查询，效率是极其低下乃至不可忍受的。再例如大型 web 网站的用户登录系统，例如腾讯，盛大，动辄数以亿计的帐号，关系数据库也很难应付。 3、High Scalability &amp;&amp; High Availability - 对数据库的高可扩展性和高可用性的需求 在基于 web 的架构当中，数据库是最难进行横向扩展的，当一个应用系统的用户量和访问量与日俱增的时候，你的数据库却没有办法像 web server 和 app server 那样简单的通过添加更多的硬件和服务节点来扩展性能和负载能力。对于很多需要提供 24 小时不间断服务的网站来说，对数据库系统进行升级和扩展是非常痛苦的事情，往往需要停机维护和数据迁移，可是停机维护随之带来的就是公司收入的减少。在上面提到的“三高”需求面前，关系数据库遇到了难以克服的障碍，而对于 web2.0 网站来说，关系数据库的很多主要特性却往往无用武之地，例如： 1、数据库事务一致性需求 、数据库事务一致性需求 很多 web 实时系统并不要求严格的数据库事务，对读一致性的要求很低，有些场合对写一致性要求也不高。因此数据库事务管理成了数据库高负载下一个沉重的负担。 2、数据库的写实时性和读实时性需求 、数据库的写实时性和读实时性需求 对关系数据库来说，插入一条数据之后立刻查询，是肯定可以读出来这条数据的，但是对于很多 web 应用来说，并不要求这么高的实时性。 3、对复杂的SQL查询，特别是多表关联查询的需求 特别是多表关联查询的需求 任何大数据量的 web 系统，都非常忌讳多个大表的关联查询，以及复杂的数据分析类型的复杂 SQL 报表查询，特别是 SNS 类型的网站，从需求以及产品设计角度，就避免了这种情况的产生。往往更多的只是单表的主键查询，以及单表的简单条件分页查询，SQL 的功能被极大的弱化了。 MongoDB的使用添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;&lt;/dependency&gt; 注入添加依赖 123456spring: data: mongodb: uri: mongodb://siss:dev.5566@39.108.210.229:27017/demo #mongodb://username:password@host:port/dbName 1234567891011@Datapublic class User &#123; private String id; private String username; private String password; private String registerTime; private String phone; private String name; private String sex; private String age;&#125; dao层依赖 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Componentpublic class UserDaoImpl &#123; @Autowired private MongoTemplate mongoTemplate; /** * 创建对象 * @param user */ public void saveUser(User user) &#123; mongoTemplate.save(user); &#125; /** * 根据用户名查询对象 * @param userName * @return */ public User findUserByUserName(String userName) &#123; Query query=new Query(Criteria.where(&quot;id&quot;).is(userName)); User user = mongoTemplate.findOne(query , User.class); return user; &#125; /** * 更新对象 * @param user */ public void updateUser(User user) &#123; Query query=new Query(Criteria.where(&quot;id&quot;).is(user.getId())); Update update= new Update().set(&quot;userName&quot;, user.getName()).set(&quot;passWord&quot;, user.getPassword()); //更新查询返回结果集的第一条 mongoTemplate.updateFirst(query,update,User.class); //更新查询返回结果集的所有 // mongoTemplate.updateMulti(query,update,User.class); &#125; /** * 删除对象 * @param id */ public void deleteUserById(Long id) &#123; Query query=new Query(Criteria.where(&quot;id&quot;).is(id)); mongoTemplate.remove(query,User.class); &#125;&#125; controller调用 123456789101112131415161718192021222324@RestControllerpublic class UserMongo &#123; @Autowired private UserDaoImpl userDao; @RequestMapping(value = &quot;mongo&quot;, method = RequestMethod.GET) public Object mongo() &#123; User user = new User(); user.setId(&quot;9&quot;); user.setAge(&quot;3&quot;); user.setName(&quot;demo&quot;); userDao.saveUser(user); return null; &#125; @RequestMapping(value = &quot;&quot;, method = RequestMethod.GET) public Object get() &#123; User user = userDao.findUserByUserName(&quot;1&quot;); return user; &#125;&#125; 实现效果插入效果： 查询的结果","categories":[],"tags":[]},{"title":"面向测试驱动开发（TDD）","slug":"doc-dev/basics/mock","date":"2018-02-25T16:00:00.000Z","updated":"2021-03-09T14:24:26.575Z","comments":true,"path":"2018/02/26/doc-dev/basics/mock/","link":"","permalink":"http://example.com/2018/02/26/doc-dev/basics/mock/","excerpt":"","text":"简介首先讲讲三个开发模式分别代表什么意思？ TDD：测试驱动开发（Test-Driven Development）测试驱动开发是敏捷开发中的一项核心实践和技术，也是一种设计方法论。TDD的原理是在开发功能代码之前，先编写单元测试用例代码，测试代码确定需要编写什么产品代码。TDD的基本思路就是通过测试来推动整个开发的进行，但测试驱动开发并不只是单纯的测试工作，而是把需求分析，设计，质量控制量化的过程。TDD首先考虑使用需求（对象、功能、过程、接口等），主要是编写测试用例框架对功能的过程和接口进行设计，而测试框架可以持续进行验证。 BDD：行为驱动开发（Behavior Driven Development）行为驱动开发是一种敏捷软件开发的技术，它鼓励软件项目中的开发者、QA和非技术人员或商业参与者之间的协作。主要是从用户的需求出发，强调系统行为。BDD最初是由Dan North在2003年命名，它包括验收测试和客户测试驱动等的极限编程的实践，作为对测试驱动开发的回应。 ATDD：验收测试驱动开发（Acceptance Test Driven Development）ATDD 只是开发人员的职责，通过单元测试用例来驱动功能代码的实现。在准备实施一个功能或特性之前，首先团队需要定义出期望的质量标准和验收细则，以明确而且达成共识的验收测试计划（包含一系列测试场景）来驱动开发人员的TDD实践和测试人员的测试脚本开发。面向开发人员，强调如何实现系统以及如何检验。 使用BDD和ATDD可以解决需求和开发脱节的问题，首先他们都是从用户的需求出发，保证程序实现效果与用户需求一致。这个过程可以使用基于BDD的自动化测试工具Cucumber。 如何集成Spring Boot使用 Mokito 来完成敏捷开发现在我使用一个我们常用的mvc框架，当我们操作调用mapper层来操作数据库的时候，是不是需要调用数据库，这样不是真正的mock测试 依赖过于复杂, 这个时候我们就要考虑使用Mokito 来mock一个方法。 service层 1234567891011121314151617181920212223242526@Servicepublic class PersonService &#123; @Autowired private PersonDao personDao; public boolean update(int id, String name) &#123; Person person = personDao.getPerson(id); if (person == null) &#123; return false; &#125; Person personUpdate = new Person(); personUpdate.setId(person.getId()); personUpdate.setName(name); return personDao.update(personUpdate); &#125; public boolean getData(int id) throws Exception &#123; Person person = personDao.getPerson(id); if (person == null) &#123; new Exception(&quot;报错了！！！&quot;); &#125; return true; &#125;&#125; dao层 123456public interface PersonDao &#123; Person getPerson(int id); boolean update(Person person);&#125; 实体类Person 12345@Datapublic class Person &#123; private int id; private String name;&#125; 现在就是我们来测试我们的service层 1234567891011121314151617181920212223242526272829303132333435//这句表示该测试类运行的时候会先加载spring框架所需的相关类库并将所有有注解的类进行自动依赖注入。@RunWith(SpringRunner.class) public class DemoTestApplicationTests &#123; /*在测试类中，我们需要在被测类对象声明的时候加上@InjectMocks，这个注解从名字 也很好理解，就是将所有的mock类注入到这个对象实例中，注意这里对APMInfoService的创建必须要通过new来初始 化，不能像@Autowired那样靠spring自动注入依赖类，因为这里APMInfoService内部依赖的类都是Mock的对象，必 须要显式创建类实例Mockito才能注入成功。这样你就会发现在下面测试方法调用的时候被测类就不会再是null了。 */ @InjectMocks private PersonService personService = new PersonService(); @Mock private PersonDao personDao; @Before public void beforeUpdate()&#123; Person person = new Person(); person.setId(1); person.setName(&quot;chulei&quot;); when(personDao.getPerson(1)).thenReturn(person); //when().thenThrow(Exception.class); when(personDao.update(person)).thenReturn(true); &#125; @Test public void update() &#123; Boolean flag = personService.update(1, &quot;chulei&quot;); Assert.assertEquals(flag, true); verify(personDao).getPerson(1); &#125;&#125; 测试controller类 1234567891011121314151617181920212223242526272829303132@WebAppConfiguration@Transactional //支持数据回滚，避免测试数据污染环境@RunWith(SpringRunner.class)@SpringBootTestpublic class DemoTestApplicationTests &#123; @Autowired private WebApplicationContext wac; private MockMvc mockMvc; @Before public void setup() &#123; mockMvc = MockMvcBuilders.webAppContextSetup(wac).build(); &#125; @Test public void sub() throws Exception &#123; String result = mockMvc.perform( get(&quot;/api/order&quot;) .param(&quot;pageNum&quot;, &quot;1&quot;) .param(&quot;pageSize&quot;, &quot;10&quot;) .param(&quot;status&quot;, &quot;1&quot;) .contentType(MediaType.APPLICATION_JSON_UTF8)) .andExpect(status().isOk()) .andExpect(jsonPath(&quot;$.code&quot;).value(10000)) .andReturn().getResponse().getContentAsString(); &#125;&#125;","categories":[],"tags":[]},{"title":"使用 Spring Boot集成 RabbitMq","slug":"doc-dev/basics/rabiit","date":"2018-02-25T16:00:00.000Z","updated":"2021-03-09T14:24:39.751Z","comments":true,"path":"2018/02/26/doc-dev/basics/rabiit/","link":"","permalink":"http://example.com/2018/02/26/doc-dev/basics/rabiit/","excerpt":"","text":"简介 AMQP，即Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。 AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 RabbitMQ是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 下面将重点介绍RabbitMQ中的一些基础概念，了解了这些概念，是使用好RabbitMQ的基础。 使用场景场景说明：用户注册后，需要发注册邮件和注册短信,传统的做法有两种 串行的方式 串行方式:将注册信息写入数据库后,发送注册邮件,再发送注册短信,以上三个任务全部完成后才返回给客户端。 这有一个问题是,邮件,短信并不是必须的,它只是一个通知,而这种做法让客户端等待没有必要等待的东西. 并行的方式 并行方式:将注册信息写入数据库后,发送邮件的同时,发送短信,以上三个任务完成后,返回给客户端,并行的方式能提高处理的时间。 假设三个业务节点分别使用50ms,串行方式使用时间150ms,并行使用时间100ms。虽然并性已经提高的处理时间,但是,前面说过,邮件和短信对我正常的使用网站没有任何影响，客户端没有必要等着其发送完成才显示注册成功,英爱是写入数据库后就返回. 应用解耦场景：双11是购物狂节,用户下单后,订单系统需要通知库存系统,传统的做法就是订单系统调用库存系统的接口. 这种做法有一个缺点: 当库存系统出现故障时,订单就会失败。(这样马云将少赚好多好多钱^ ^)订单系统和库存系统高耦合.引入消息队列 订单系统:用户下单后,订单系统完成持久化处理,将消息写入消息队列,返回用户订单下单成功。 库存系统:订阅下单的消息,获取下单消息,进行库操作。就算库存系统出现故障,消息队列也能保证消息的可靠投递,不会导致消息丢失(马云这下高兴了). 流量削峰流量削峰一般在秒杀活动中应用广泛场景:秒杀活动，一般会因为流量过大，导致应用挂掉,为了解决这个问题，一般在应用前端加入消息队列。作用: 可以控制活动人数，超过此一定阀值的订单直接丢弃(我为什么秒杀一次都没有成功过呢^^) 可以缓解短时间的高流量压垮应用(应用程序按自己的最大处理能力获取订单) 用户的请求,服务器收到之后,首先写入消息队列,加入消息队列长度超过最大值,则直接抛弃用户请求或跳转到错误页面. 秒杀业务根据消息队列中的请求信息，再做后续处理. SpringBoot 集成RabbitMq添加依赖pom.xml 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 添加数据库连接application.yml 12345678910spring: rabbitmq: host: youhostname port: 5672 username: test password: dev.5566 virtual-host: / publisher-returns: true template: mandatory: true 添加topic config持久化该队列 12345678910111213141516171819202122232425262728293031@Configurationpublic class RabbitConfig &#123; //声明队列 @Bean public Queue queue1() &#123; return new Queue(&quot;hello.queue1&quot;, true); // true表示持久化该队列 &#125; @Bean public Queue queue2() &#123; return new Queue(&quot;hello.queue2&quot;, true); &#125; //声明交互器 @Bean TopicExchange topicExchange() &#123; return new TopicExchange(&quot;topicExchange&quot;); &#125; //绑定 @Bean public Binding binding1() &#123; return BindingBuilder.bind(queue1()).to(topicExchange()).with(&quot;key.1&quot;); &#125; @Bean public Binding binding2() &#123; return BindingBuilder.bind(queue2()).to(topicExchange()).with(&quot;key.#&quot;); &#125;&#125; 发送消息message 12345678910111213141516171819202122232425262728293031323334353637@Componentpublic class Sender implements ConfirmCallback, ReturnCallback &#123; @Autowired private RabbitTemplate rabbitTemplate; @PostConstruct public void init() &#123; rabbitTemplate.setConfirmCallback(this); rabbitTemplate.setReturnCallback(this); &#125; @Override public void confirm(CorrelationData correlationData, boolean b, String s) &#123; if (b) &#123; System.out.println(&quot;消息发送成功:&quot; + correlationData); &#125; else &#123; System.out.println(&quot;消息发送失败:&quot; + s); &#125; &#125; @Override public void returnedMessage(Message message, int i, String s, String s1, String s2) &#123; &#125; public void send(String msg)&#123; CorrelationData correlationId = new CorrelationData(UUID.randomUUID().toString()); System.out.println(&quot;开始发送消息 : &quot; + msg.toLowerCase()); String response = rabbitTemplate.convertSendAndReceive(&quot;topicExchange&quot;, &quot;key.1&quot;, msg, correlationId).toString(); System.out.println(&quot;结束发送消息 : &quot; + msg.toLowerCase()); System.out.println(&quot;消费者响应 : &quot; + response + &quot; 消息处理完成&quot;); &#125;&#125; 消息接受方 1234567891011@Componentpublic class Receiver &#123; @RabbitListener(queues = &quot;hello.queue1&quot;) public String processMessage1(String msg) &#123; System.out.println(Thread.currentThread().getName() + &quot; 接收到来自hello.queue1队列的消息：&quot; + msg); return msg.toUpperCase(); &#125;&#125; controller类 12345678910111213@RestControllerpublic class RabbitMqController &#123; @Autowired private Sender sender; @RequestMapping(value = &quot;/rabbit&quot;, method = RequestMethod.GET) public void rabbit() &#123; sender.send(&quot;ss&quot;); &#125;&#125; 测试结果1234开始发送消息 : ssSimpleAsyncTaskExecutor-1 接收到来自hello.queue1队列的消息：ss结束发送消息 : ss消费者响应 : SS 消息处理完成","categories":[],"tags":[]},{"title":"结合Mybatis-Plus 使用读写分离","slug":"doc-dev/basics/mybatis-plus","date":"2018-02-22T16:00:00.000Z","updated":"2021-03-09T14:25:27.421Z","comments":true,"path":"2018/02/23/doc-dev/basics/mybatis-plus/","link":"","permalink":"http://example.com/2018/02/23/doc-dev/basics/mybatis-plus/","excerpt":"","text":"简介Mybatis-Plus（简称MP）是一个 Mybatis 的增强工具，在 Mybatis 的基础上只做增强不做改变，为简化开发、提高效率而生。这是官方给的定义，关于mybatis-plus的更多介绍及特性，可以参考mybatis-plus官网。那么它是怎么增强的呢？其实就是它已经封装好了一些crud方法，我们不需要再写xml了，直接调用这些方法就行，就类似于JPA。 Mybatis-Plus的使用使用SpringBoot 集成Mybatis-Plus。 首先添加Mybatis-Plus依赖 123456789101112131415161718192021222324252627282930 &lt;dependency&gt; &lt;groupId&gt;cn.com.siss&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mybatis-plus&lt;/artifactId&gt; &lt;version&gt;$&#123;starters.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;!-- 有兴趣的也可以使用mybatis的自动生成代码工具 Mybatis Generator --&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;configuration&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;!--指定资源的位置--&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; 扫描实体类（entity）和 数据库（mapper）包路径 12345678910spring: profiles: include: - mybatisplus-rwsmybatis: typeAliasesPackage: &quot;cn.com.siss.web.entity&quot; #checkConfig-location : false mapper-locations: &quot;classpath:cn/com/siss/web/mapper/xml/*Mapper.xml&quot; 在启动类加注解@MapperScan(&quot;cn.com.siss.web.mapper*&quot;) 扫描数据层。 123456789@SpringBootApplication@MapperScan(&quot;cn.com.siss.web.mapper*&quot;)public class DemoWebApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoWebApplication.class, args); &#125;&#125; 添加数据库连接信息（name , username, password），例如： 12345678910111213app: datasource: name: demo #数据库名称 read: host: mysql-ro-local # 读 数据库的 host 默认为： mysql-ro-$&#123;spring.active.profile&#125; port: 3306 # 读 数据库的 port 默认为： 3306 write: host: mysql-local # 写 数据库的 host 默认为： mysql-$&#123;spring.active.profile&#125; port: 3307 # 写 数据库的 port 默认为： 3306 username: root password: gUa7c4GulFZluORvMIEdC5Jm6P7UMs0VfCHErThG2AUz/DOvb/e0dHkcBGmtmzyURYQXTxxQngjR4+ccYc/J1Q== druid: public-key: MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAJc1VMKK8to2/8IjwA/7QG8qASZl0PWGnZKgNruPAJxAmQQtEMvsFGu6uD3rTfCbFrD4CtNuNz0B3bX067oQZI0CAwEAAQ== 这里数据库密码需要加密，禁止使用明文密码： 下载durid.jar包 druid.jar下载成功后在当前目录执行 12345java -cp druid-1.1.9.jar com.alibaba.druid.filter.config.ConfigTools yourpasswordprivateKey:MIIBVQIBADANBgkqhkiG9w0BAQEFAASCAT8wggE7AgEAAkEAiVDuSXMyYybL6zxlGvOwAOuxTyWeOKCXWYv5+Kfwz2CE08+UczVi07GmMlUT5Z3RxpEuDKKqVYylAgpC7D8QwQIDAQABAkBRDwxLIYyKCVnxGCra+SVZtchqX1uCNBKEEuRSC9lUoNaAhSzUrS6uX9eqlGYaFB11iRUmO33PFX2tJe4ez3nRAiEA2ittzLPt9kbh8t3ZAysr5KUpG4m7Xclfij+pvMbrJU0CIQChIGg0CD2CUtdSwXMlv34VzVuWdNglNFZdSoWqJSiPRQIgL/hgmiPt7LrFL6uL7eBuNEYEdeOg6QxAD5vT7IgoZ/kCIQCBQ391ptq5z/4A3UOkmADuOsbsaKbzCg7zXxLm0lK8xQIhAL1hb6D4zkzDhMXBuWKXX1sf+yPXr5uqNOk7Qd1DyFzopublicKey:MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAIlQ7klzMmMmy+s8ZRrzsADrsU8lnjigl1mL+fin8M9ghNPPlHM1YtOxpjJVE+Wd0caRLgyiqlWMpQIKQuw/EMECAwEAAQ==password:IAsFFJu/MU7b3yXUp+v3AiGzxRxp3C/C6W2CXUPyrfH8V52CloF/JAoV4gNvEWUunQkBFYDX6KwgF+7KYJopjg== 把上面的publicKey和password分别粘贴到application.yml中 mapper.java 123456789import cn.com.siss.web.entity.TbDemo;public interface TbDemoMapper &#123; int insert(TbDemo record); int insertSelective(TbDemo record); TbDemo get(Integer id);&#125; mapper.xml 1234567891011121314151617181920212223242526272829303132333435&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;cn.com.siss.web.mapper.TbDemoMapper&quot;&gt; &lt;resultMap id=&quot;BaseResultMap&quot; type=&quot;cn.com.siss.web.entity.TbDemo&quot;&gt; &lt;result column=&quot;id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;id&quot; /&gt; &lt;result column=&quot;name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;name&quot; /&gt; &lt;/resultMap&gt; &lt;insert id=&quot;insert&quot; parameterType=&quot;cn.com.siss.web.entity.TbDemo&quot;&gt; insert into tb_demo (id, name) values (#&#123;id,jdbcType=INTEGER&#125;, #&#123;name,jdbcType=VARCHAR&#125;) &lt;/insert&gt; &lt;insert id=&quot;insertSelective&quot; parameterType=&quot;cn.com.siss.web.entity.TbDemo&quot;&gt; insert into tb_demo &lt;trim prefix=&quot;(&quot; suffix=&quot;)&quot; suffixOverrides=&quot;,&quot;&gt; &lt;if test=&quot;id != null&quot;&gt; id, &lt;/if&gt; &lt;if test=&quot;name != null&quot;&gt; name, &lt;/if&gt; &lt;/trim&gt; &lt;trim prefix=&quot;values (&quot; suffix=&quot;)&quot; suffixOverrides=&quot;,&quot;&gt; &lt;if test=&quot;id != null&quot;&gt; #&#123;id,jdbcType=INTEGER&#125;, &lt;/if&gt; &lt;if test=&quot;name != null&quot;&gt; #&#123;name,jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;/trim&gt; &lt;/insert&gt; &lt;select id=&quot;get&quot; parameterType=&quot;integer&quot; resultType=&quot;cn.com.siss.web.entity.TbDemo&quot;&gt; select * from tb_demo where id = #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; 测试用例 12345678910111213141516@Autowiredprivate TbDemoMapper tbDemoMapper;@Testpublic void get() &#123; TbDemo tbDemo = tbDemoMapper.get(1); System.out.println(tbDemo.getName());&#125;@Testpublic void insert() &#123; TbDemo tbDemo = new TbDemo(); tbDemo.setId(1); tbDemo.setName(&quot;aa&quot;); tbDemoMapper.insert(tbDemo);&#125;","categories":[],"tags":[]},{"title":"使用SpringBoot 整合 消息中间件Kafka","slug":"doc-dev/basics/kafka","date":"2018-02-19T16:00:00.000Z","updated":"2021-03-09T14:24:10.265Z","comments":true,"path":"2018/02/20/doc-dev/basics/kafka/","link":"","permalink":"http://example.com/2018/02/20/doc-dev/basics/kafka/","excerpt":"","text":"简介Kafka is a distributed,partitioned,replicated commit logservice。它提供了类似于JMS的特性，但是在设计实现上完全不同，此外它并不是JMS规范的实现。kafka对消息保存时根据Topic进行归类，发送消息者成为Producer,消息接受者成为Consumer,此外kafka集群有多个kafka实例组成，每个实例(server)成为broker。无论是kafka集群，还是producer和consumer都依赖于zookeeper来保证系统可用性集群保存一些meta信息。 使用场景Kafka主要特点 同时为发布和订阅提供高吞吐量。据了解，Kafka每秒可以生产约25万消息（50 MB），每秒处理55万消息（110 MB）。 可进行持久化操作。将消息持久化到磁盘，因此可用于批量消费，例如ETL，以及实时应用程序。通过将数据持久化到硬盘以及replication防止数据丢失。 分布式系统，易于向外扩展。所有的producer、broker和consumer都会有多个，均为分布式的。无需停机即可扩展机器。 消息被处理的状态是在consumer端维护，而不是由server端维护。当失败时能自动平衡。 支持online和offline的场景。 SpringBoot 集成Kafka添加kafka starter依赖 12345&lt;dependency&gt; &lt;groupId&gt;cn.com.siss&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-kafka&lt;/artifactId&gt; &lt;version&gt;$&#123;starters.version&#125;&lt;/version&gt;&lt;/dependency&gt; 添加kafka配置文件 1234spring: profiles: include: - kafka 发送消息 注册kafkaTemplate kafkaTemplate.send(&quot;message&quot;, &quot;hello-world&quot;) 123456789@Autowiredprivate KafkaTemplate kafkaTemplate;@RequestMapping(value = &quot;/sendKafka&quot;, method = RequestMethod.GET)public Object sendKafka()&#123; System.out.println(&quot;sendKafka&quot;); ListenableFuture result = kafkaTemplate.send(&quot;message&quot;, &quot;hello-world&quot;); return result;&#125; 消息接受者 12345678910111213141516@Component@Slf4jpublic class Hellokafka &#123; @KafkaListener(topics = &#123;&quot;message&quot;&#125;) public void getMessage(ConsumerRecord&lt;?, ?&gt; record) &#123; Optional&lt;?&gt; kafkaMessage = Optional.ofNullable(record.value()); if (kafkaMessage.isPresent()) &#123; Object message = kafkaMessage.get(); log.info(&quot;----------------- record =&quot; + record); log.info(&quot;------------------ message =&quot; + message); &#125; &#125;&#125; 效果如下 12345678sendKafka2019-02-28 17:20:07.013 INFO 10477 --- [nio-8081-exec-1] o.a.k.clients.producer.ProducerConfig : ProducerConfig values:2019-02-28 17:20:07.020 INFO 10477 --- [nio-8081-exec-1] o.a.k.clients.producer.ProducerConfig : ProducerConfig values:2019-02-28 17:20:07.020 INFO 10477 --- [nio-8081-exec-1] o.a.kafka.common.utils.AppInfoParser : Kafka version : 0.10.0.12019-02-28 17:20:07.020 INFO 10477 --- [nio-8081-exec-1] o.a.kafka.common.utils.AppInfoParser : Kafka commitId : a7a17cdec9eaa6c52019-02-28 17:20:07.398 INFO 10477 --- [afka-listener-1] cn.com.siss.web.kafka.Hellokafka : ----------------- record &#x3D;ConsumerRecord(topic &#x3D; message, partition &#x3D; 0, offset &#x3D; 85, CreateTime &#x3D; 1551345607273, checksum &#x3D; 3403921507, serialized key size &#x3D; -1, serialized value size &#x3D; 11, key &#x3D; null, value &#x3D; hello-world)2019-02-28 17:20:07.398 INFO 10477 --- [afka-listener-1] cn.com.siss.web.kafka.Hellokafka : ------------------ message &#x3D;hello-world2019-02-28 17:20:07.434 WARN 10477 --- [nio-8081-exec-2] .w.s.m.s.DefaultHandlerExceptionResolver : Failed to write HTTP message: org.springframework.http.converter.HttpMessageNotWritableException: Could not write JSON: No serializer found for class org.apache.kafka.clients.producer.ProducerRecord and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS); nested exception is com.fasterxml.jackson.databind.JsonMappingException: No serializer found for class org.apache.kafka.clients.producer.ProducerRecord and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) (through reference chain: org.springframework.kafka.support.SendResult[&quot;producerRecord&quot;])","categories":[],"tags":[]},{"title":"2 GIT 的使用","slug":"doc-dev/basics/git","date":"2018-02-19T16:00:00.000Z","updated":"2021-03-09T14:24:00.617Z","comments":true,"path":"2018/02/20/doc-dev/basics/git/","link":"","permalink":"http://example.com/2018/02/20/doc-dev/basics/git/","excerpt":"","text":"2.1 概述如果你严肃对待编程，就必定会使用”版本管理系统”（Version Control System）。眼下最流行的”版本管理系统”，非Git莫属。 相比同类软件，Git有很多优点。其中很显著的一点，就是版本的分支（branch）和合并（merge）十分方便。有些传统的版本管理软件，分支操作实际上会生成一份现有代码的物理拷贝，而Git只生成一个指向当前版本（又称”快照”）的指针，因此非常快捷易用。但是，太方便了也会产生副作用。如果你不加注意，很可能会留下一个枝节蔓生、四处开放的版本库，到处都是分支，完全看不出主干发展的脉络。 Vincent Driessen提出了一个分支管理的策略，我觉得非常值得借鉴。它可以使得版本库的演进保持简洁，主干清晰，各个分支各司其职、井井有条。理论上，这些策略对所有的版本管理系统都适用，Git只是用来举例而已。如果你不熟悉Git，跳过举例部分就可以了。 2.2 Git 的安装Git 下载 下载成功后直接点击安装即可。 2.3 Git 注册及配置在浏览器输入https://gitlab.sissyun.com.cn 打开Gitlab客户端 2.4 注册特别注意下面的格式，名字用中文，用户名使用全小写拼音, 并使用公司邮箱。如果你的名字是：张三， 姓名（name）填写中文名：张三 用户名（username）填写你的全名拼音：zhangsan 邮箱是使用公司邮箱，不要用私人邮箱：&#122;&#x68;&#97;&#x6e;&#x67;&#x2e;&#115;&#x61;&#110;&#x40;&#115;&#x73;&#105;&#46;&#x63;&#111;&#109;. 请记住自己设置的密码，要求8位，并包含英文字母大、小写及数字，如：pA5wOldy，如果你没安装要求注册，你将无法登录Gitlab。 2.5 激活用户激活你的账户 接下来去邮箱查看你的邮件，你很快会收到来自 Gitlab 的邮件,按照提示激活你的账户。（如果没收到激活邮件，请联系你的项目经理） 2.6 设置密钥回到操作系统命令提示符下（windows用户请用git bash终端）生成ssh密钥及设置git用户信息, 注意如果你在运行ssh-keygen是设置了密码，那么你以后的git操作也要输入密码，否则这里可以直接回车，即运行ssh-keygen不使用密码。 123ssh-keygen -t rsa -C &quot;zhang.san@ssi.com&quot; git config --global user.name &quot;Zhang San&quot;git config --global user.email &quot;zhang.san@ssi.com&quot; 2.7 上传公钥登录gitlab后，先点击 Profile Settings &gt; 创建rsa 密钥 1ssh-keygen -t rsa -C &quot;youname@ssi.com&quot; \b最好打开密钥管理页面 在git bash下，复制刚才生成好的ssh公共密钥的文本内容并粘贴到下面文本框内 Windows：c:\\Users\\yourname.ssh\\id_rsa.pub; Linux/Mac: ~/.ssh/id_rsa.pub 12cat ~/.ssh/id_rsa.pub 2.8 编辑Git配置文件我们来克隆一个演示应用代码下来测试 1git clone ssh://git@gitlab.sissyun.com.cn:8022/frameworks/spring-boot-utils.git 2.9 Git 使用\b入门说明： 以下所有git命令行都在终端下操作。 创建分支 创建一个名称叫 demo 1git checkout -b demo 查看创建的分支 1git branch –a 查看本地文件修改状态 接下来就可以开发了，开发完成后查看更改过的文件 1git status 代码提交审查没有问题后提交代码到 feature 分支 12345678910111213git add .git statusgit commit(press i to input below text)[Description]: Your comments.[Reviewer]: The name of reviewer(press esc and :wq to commit ) 把提交到代码推到远程服务器 1git push origin demo 主分支master 首先，代码库应该有一个、且仅有一个主分支。所有提供给用户使用的正式版本，都在这个主分支上发布。 Git主分支的名字，默认叫做master。它是自动建立的，版本库初始化以后，默认就是在主分支在进行开发。 开发分支development 主分支只用来分布重大版本，日常开发应该在另一条分支上完成。我们把开发用的分支，叫做development, 开发功能模块应该新建feature分支，单元测试通过后合并到development分支，合并完成后feature分支到生命周期结束，应该删除该分支。 这个分支可以用来生成代码的最新隔夜版本（nightly）。如果想正式对外发布，就在Master分支上，对Development分支进行”合并”（merge）。Git创建Development分支的命令： 1git checkout -b development 将Development分支发布到Master分支的命令： 12345# 切换到Master分支git checkout master# 对Development分支进行合并git merge --no-ff development 这里稍微解释一下，上一条命令的–no-ff参数是什么意思。默认情况下，Git执行”快进式合并”（fast-farward merge），会直接将Master分支指向Develop分支。 使用–no-ff参数后，会执行正常合并，在Master分支上生成一个新节点。为了保证版本演进的清晰，我们希望采用这种做法。关于合并的更多解释，请参考Benjamin Sandofsky的《Understanding the Git Workflow》。 临时性分支 前面讲到版本库的两条主要分支：Master和Development。前者用于正式发布，后者用于日常开发。其实，常设分支只需要这两条就够了，不需要其他了。但是，除了常设分支以外，还有一些临时性分支，用于应对一些特定目的的版本开发。临时性分支主要有三种： 功能（feature）分支 预发布（release）分支 修补bug（fixbug）分支 这三种分支都属于临时性需要，使用完以后，应该删除，使得代码库的常设分支始终只有Master和Development。 功能分支 接下来，一个个来看这三种”临时性分支”。第一种是功能分支，它是为了开发某种特定功能，从Development分支上面分出来的。开发完成后，要再并入Development。 功能分支的名字，可以采用feature-*的形式命名。创建一个功能分支： 1git checkout -b feature-x development 开发完成后，将功能分支合并到development分支： 12git checkout developmentgit merge --no-ff feature-x 删除feature分支： 1git branch -d feature-x 2.2.3.5 预发布分支 第二种是预发布分支，它是指发布正式版本之前（即合并到Master分支之前），我们可能需要有一个预发布的版本进行测试。预发布分支是从Development分支上面分出来的，预发布结束以后，必须合并进Development和Master分支。它的命名，可以采用release-*的形式。创建一个预发布分支： 1git checkout -b release-1.0.0 development 确认没有问题后，合并到master分支： 1234git checkout mastergit merge --no-ff release-1.0.0# 对合并生成的新节点，做一个标签git tag -a 1.0.0 再合并到development分支： 12git checkout developmentgit merge --no-ff release-1.0.0 最后，删除预发布分支： 1git branch -d release-1.0.0 修补bug分支 第三种是修补bug分支。软件正式发布以后，难免会出现bug。这时就需要创建一个分支，进行bug修补。修补bug分支是从Master分支上面分出来的。修补结束以后，再合并进Master和Development分支。它的命名，可以采用fixbug-*的形式。 创建一个修补bug分支： 1 git checkout -b fixbug-0.1 master 修补结束后，合并到master分支： 123 git checkout master git merge --no-ff fixbug-0.1 git tag -a 0.1.1 再合并到development分支： 12 git checkout development git merge --no-ff fixbug-0.1 最后，删除”修补bug分支”： 1 git branch -d fixbug-0.1 客户稳定版分支 当应用发布给多个客户上线时，我们需要从master\b\b创建客户分支 abc-xxx分支是从 master 分支上面分出来的，它的命名，可以采用abc-xxx的形式（abc为客户项目\b代码, xxx为版本号）。 创建一个预发布分支： 1 git checkout -b abc-1.0.0 master 测试\b有问题就在这个分支收敛再提交测\b试，最后测试没有问题，以此版本发布。","categories":[],"tags":[]},{"title":"GRPC的使用","slug":"doc-dev/basics/grpc","date":"2018-02-19T16:00:00.000Z","updated":"2021-03-09T14:24:06.656Z","comments":true,"path":"2018/02/20/doc-dev/basics/grpc/","link":"","permalink":"http://example.com/2018/02/20/doc-dev/basics/grpc/","excerpt":"","text":"简介grpc 由 google 开发,是一款语言中立、平台中立、开源的远程过程调用(RPC)系统。它是一个高性能、开源和通用的RPC框架，面向移动和HTTP/2设计。目前提供C、Java和Go语言版本，分别是grpc、grpc-java、grpc-go。gRPC基于HTTP/2标准设计，带来诸如双向流、流控、头部压缩、单TCP连接上的多复用请求等特性。 grpc的使用本章主要结合java中 的SpringBoot 集成 grpc而展开。 数据结构对应表|.proto类型|Java 类型|C++类型|备注||—|—|—|—|—||double|double|double|||float|float|float|||int32|int|int32|使用可变长编码方式。编码负数时不够高效——如果你的字段可能含有负数，那么请使用sint32。||int64|long|int64|使用可变长编码方式。编码负数时不够高效——如果你的字段可能含有负数，那么请使用sint64。||uint32|int[1]|uint32|Uses variable-length encoding.||uint64|long[1]|uint64|Uses variable-length encoding.||sint32|int|int32|使用可变长编码方式。有符号的整型值。编码时比通常的int32高效。||sint64|long|int64|使用可变长编码方式。有符号的整型值。编码时比通常的int64高效。||fixed32|int[1]|uint32|总是4个字节。如果数值总是比总是比228大的话，这个类型会比uint32高效。||fixed64|long[1]|uint64|总是8个字节。如果数值总是比总是比256大的话，这个类型会比uint64高效。||sfixed32|int|int32|总是4个字节。||sfixed64|long|int64|总是8个字节。||bool|boolean|bool|||string|String|string|一个字符串必须是UTF-8编码或者7-bit ASCII编码的文本。||bytes|ByteString|string|可能包含任意顺序的字节数据。| 新建项目首先通过ideal创建一个springboot的项目。 填写 包名 组名等基本信息。 项目的编写创建好项目后 修改 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;!-- 父包名称 --&gt; &lt;parent&gt; &lt;groupId&gt;cn.com.siss&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starters&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;cn.com.siss&lt;/groupId&gt; &lt;artifactId&gt;demo-grpc&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;demo-grpc&lt;/name&gt; &lt;!-- packaging 为 pom --&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!-- 子模块 --&gt; &lt;modules&gt; &lt;module&gt;demo-api&lt;/module&gt; &lt;module&gt;demo-provider&lt;/module&gt; &lt;module&gt;demo-web&lt;/module&gt; &lt;/modules&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.com.siss&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-grpc&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.com.siss.utils&lt;/groupId&gt; &lt;artifactId&gt;siss-utils&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 添加子模块 demo-api 该模块主要存放实体类 proto文件 修改 demo-api 的 pom.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;!-- 修改parent --&gt; &lt;parent&gt; &lt;groupId&gt;cn.com.siss&lt;/groupId&gt; &lt;artifactId&gt;demo-grpc&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt;&lt;!-- 添加依赖 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;!-- 添加插件 --&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;classifier&gt;exec&lt;/classifier&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.sonarsource.scanner.maven&lt;/groupId&gt; &lt;artifactId&gt;sonar-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.jacoco&lt;/groupId&gt; &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; demo-web 对外提供接口 对外api 12345678910111213@RestControllerpublic class HelloWorld &#123; @Autowired private HelloRpcService helloRpcService; @RequestMapping(value = &quot;/&quot;, method = RequestMethod.GET) public String get()&#123; System.out.println(&quot;controller get method&quot;); String b = helloRpcService.get(&quot;qq&quot;); return b; &#125;&#125; rpc层对java对象转化为proto流文件 123456789101112131415@Service@Slf4j@AllArgsConstructorpublic class HelloRpcService &#123; private HelloServiceGrpc.HelloServiceBlockingStub blockingStub; public String get(String name) &#123; Hello hello = new Hello(); hello.setName(name); HelloProto.HelloDTO dto = (HelloProto.HelloDTO) toGRpcMessage(hello, HelloProto.HelloDTO.newBuilder()); HelloProto.HelloDTO rep = blockingStub.get(dto); String say = (String) fromGRpcMessage(rep, String.class); return say; &#125;&#125; 定义protobuf 123456789101112syntax = &quot;proto3&quot;;option java_package = &quot;cn.com.siss.api&quot;;option java_outer_classname = &quot;HelloProto&quot;;message HelloDTO &#123; string name = 1;&#125;service HelloService &#123; rpc get (HelloDTO) returns (HelloDTO) &#123;&#125;&#125; 添加config文件注册 123456789101112@Configuration@EnableAutoConfigurationpublic class HelloConfig &#123; @GRpcClient(&quot;demo-provider&quot;) private ManagedChannel channel; @Bean public HelloServiceGrpc.HelloServiceBlockingStub helloServiceBlockingStub()&#123; return HelloServiceGrpc.newBlockingStub(channel); &#125;&#125; 修改application.yml 12345678grpc: client: demo-provider: server-host: localhost server-port: 7575 enable-keep-alive: true keep-alive-delay: 60 # seconds keep-alive-timeOut: 60 demo-provider 对数据做持久化 修改pom文件 12345678910111213141516171819202122232425262728293031323334353637&lt;parent&gt; &lt;groupId&gt;cn.com.siss&lt;/groupId&gt; &lt;artifactId&gt;demo-grpc&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;!-- 添加依赖 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.com.siss&lt;/groupId&gt; &lt;artifactId&gt;demo-api&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; rpc层 12345678910111213@Slf4j@GRpcServicepublic class HelloRpc extends HelloServiceGrpc.HelloServiceImplBase &#123; @Override public void get(HelloProto.HelloDTO request, StreamObserver&lt;HelloProto.HelloDTO&gt; responseObserver) &#123; HelloProto.HelloDTO response = (HelloProto.HelloDTO) toGRpcMessage(request, HelloProto.HelloDTO.newBuilder()); responseObserver.onNext(response); responseObserver.onCompleted(); &#125;&#125; 可以尝试下载demo debug一下 1git clone ssh://git@gitlab.sissyun.com.cn:8022/demo/demo-grpc.git","categories":[],"tags":[]}],"categories":[{"name":"istio","slug":"istio","permalink":"http://example.com/categories/istio/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"http://example.com/tags/kubernetes/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"kernel","slug":"kernel","permalink":"http://example.com/tags/kernel/"},{"name":"network","slug":"network","permalink":"http://example.com/tags/network/"},{"name":"kernal","slug":"kernal","permalink":"http://example.com/tags/kernal/"},{"name":"iptables","slug":"iptables","permalink":"http://example.com/tags/iptables/"},{"name":"kiali","slug":"kiali","permalink":"http://example.com/tags/kiali/"},{"name":"istio","slug":"istio","permalink":"http://example.com/tags/istio/"},{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"}]}